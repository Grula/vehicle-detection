% Format teze zasnovan je na paketu memoir
% http://tug.ctan.org/macros/latex/contrib/memoir/memman.pdf ili
% http://texdoc.net/texmf-dist/doc/latex/memoir/memman.pdf
% 
% Prilikom zadavanja klase memoir, navedenim opcijama se podešava 
% veličina slova (12pt) i jednostrano štampanje (oneside).
% Ove parametre možete menjati samo ako pravite nezvanične verzije
% mastera za privatnu upotrebu (na primer, u b5 varijanti ima smisla 
% smanjiti 
\documentclass[12pt,oneside]{memoir} 

\DeclareUnicodeCharacter{0301}{*************************************}
% Paket koji definiše sve specifičnosti master rada Matematičkog fakulteta
\usepackage[latinica]{matfmaster} 

\usepackage{graphicx}

\usepackage{subcaption}

\usepackage{multirow}

\usepackage{textcomp}
\usepackage{pbox}


\usepackage{amsfonts}
\usepackage{amsmath}

\newcommand{\yolo}{\ensuremath{\,\textrm{YOLO}}}
\newcommand{\bvs}{\ensuremath{\,\textrm{BVS}}}
%
% Podrazumevano pismo je ćirilica.
%   Ako koristite pdflatex, a ne xetex, sav latinički tekst na srpskom jeziku
%   treba biti okružen sa \lat{...} ili \begin{latinica}...\end{latinica}.
%
% Opicija [latinica]:
%   ako želite da pišete latiniciom, dodajte opciju "latinica" tj.
%   prethodni paket uključite pomoću: \usepackage[latinica]{matfmaster}.
%   Ako koristite pdflatex, a ne xetex, sav ćirilički tekst treba biti
%   okružen sa \cir{...} ili \begin{cirilica}...\end{cirilica}.
%
% Opcija [biblatex]:
%   ako želite da koristite reference na više jezika i umesto paketa
%   bibtex da koristite BibLaTeX/Biber, dodajte opciju "biblatex" tj.
%   prethodni paket uključite pomoću: \usepackage[biblatex]{matfmaster}
%
% Opcija [b5paper]:
%   ako želite da napravite verziju teze u manjem (b5) formatu, navedite
%   opciju "b5paper", tj. prethodni paket uključite pomoću: 
%   \usepackage[b5paper]{matfmaster}. Tada ima smisla razmisliti o promeni
%   veličine slova (izmenom opcije 12pt na 11pt u \documentclass{memoir}).
%
% Naravno, opcije je moguće kombinovati.
% Npr. \usepackage[b5paper,biblatex]{matfmaster}

% Pomoćni paket koji generiše nasumičan tekst u kojem se javljaju sva slova
% azbuke (nema potrebe koristiti ovo u pravim disertacijama)
% \usepackage[latinica]{pangrami}

% Datoteka sa literaturom u BibTex tj. BibLaTeX/Biber formatu
\bib{matfmaster}

% Ime kandidata na srpskom jeziku (u odabranom pismu)
\autor{Nikola Grulović}
% Naslov teze na srpskom jeziku (u odabranom pismu)
\naslov{Tehnike augmentacije i kreiranja podataka za detekciju objekata}
% Godina u kojoj je teza predana komisiji
\godina{2022}
% Ime i afilijacija mentora (u odabranom pismu)
\mentor{dr Milena \textsc{Vujošević Janičić}, vandredni profesor\\ Univerzitet u Beogradu, Matematički fakultet}
\komisijaA{dr Mladen \textsc{Nikolić}, vandredni profesor\\ Univerzitet u Beogradu, Matematički fakultet}
\komisijaB{Lester de \textsc{Abreu Faria}, Professor at ITA \& PHD in Microelectronics\\ IPFacens, Sorocaba, São Paulo, Brazil}
% Datum odbrane (odkomentarisati narednu liniju i upisati datum odbrane ako je poznat)
\datumodbrane{Septembar, 2022.}

\apstr{
Automatska detekcija i prepoznavanje objekata ima veoma važnu ulogu u svakodnevnom životu.
Jedan od najznačajnijih primera korišćenja detekcije i prepoznavanja objekata je kod autonomne vožnje. 
Da bi se omogućilo efikasno prepoznavanje objekata, koriste se metode mašinskog učenja, na primer neuronske mreže, duboko učenje i metode računarskog vida.
Međutim, da bi se dobili rezultati u skladu sa željenim kvalitetom, obično je neophodna velika količina podataka, velika procesorska snaga i obeležavanje podataka koje može da bude veoma skupo ili u velikoj meri nedostupno. 
Ovaj rad se bavi metodama za proširivanje skupa podataka, kao i metodama za smanjenje vremena potrebnog za obučavanje modela, u slučaju da velika količina podataka ili velika procesorska snaga nisu na raspolaganju.
U radu se podaci proširuju standardnim transformacijama za slike i metodama kreiranja novih sintetičkih podataka.
Korišćenjem obuke sa prenosom znanja smanjuje se vreme koje je potrebno neuronskim mrežama da nauče glavne karakteristike raspoloživih podataka.
Korišćenjem navedenih metoda dobijaju se poboljšani rezultati u odnosu na trenutno najbolji model za detekciju objekata. Poboljšanja modela se ogledaju u boljoj detekciji i u boljem prepoznavanju objekata.
}

\kljucnereci{veštačka inteligencija, mašinsko učenje, računarski vid, duboko učenje, digitalna slika, VGG16, YOLO, StyleGAN}

\begin{document}
% ==============================================================================
% Uvodni deo teze
\frontmatter
% ==============================================================================
% Naslovna strana
\naslovna
% Strana sa podacima o mentoru i članovima komisije
\komisija
% Strana sa posvetom (u odabranom pismu)
\posveta{}
% Strana sa podacima o disertaciji na srpskom jeziku
\apstrakt
% Sadržaj teze
\tableofcontents*

% ==============================================================================
% Glavni deo teze
\mainmatter
% ==============================================================================


% ------------------------------------------------------------------------------
\chapter{Uvod}
% ------------------------------------------------------------------------------

Mašinsko učenje (eng.~\textit{machine learning}) se odnosi na sposobnost mašine da donosi zaključke koristeći dostupne podatke umesto strogo definisanih i kodiranih pravila. Zapravo, mašinsko učenje omogućava računarima da sami uče. 
Rezultati mašinskog učenja posredno se javljaju u svakodnevnom životu, od predviđanja vremenske prognoze do autonomne vožnje.

Tehnike nadgledanog mašinskog učenja podrazumevaju korišćenje velike količine označenih podataka. Međutim, postoji više razloga zbog kojih velika količina označenih podataka nije uvek dostupna. Prikupljanje i obeležavanje podataka je proces koji može biti izuzetno skup ili čak i nemoguć \cite{bengio2007scaling}. Na primer, u oblasti medicine, obeležavanje podataka od strane stručnjaka radiologije je skupo i nije izvodljivo u velikim razmerama \cite{litjens2017survey}. U takvim situacijama, mašinsko učenje ima na raspolaganju samo malu količinu podataka i potrebno je primeniti posebne tehnike i pristupe kako bi se problem dostupnosti male količine podataka, ukoliko je to moguće, prevazišao. 

U ovom radu se rešava problem dostupnosti male količine podataka, pri čemu su podaci slike sa obeleženim okvirima objekata. Za rešavanje problema male količine podataka koriste se dva pristupa: proširivanje skupa podataka i učenje sa prenosom znanja (eng.~\textit{transfer learning}).
U radu je opisan postupak proširivanja skupa podataka, pri čemu se podaci proširuju standardnim transformacijama za augmentaciju slika i podacima dobijenim pomoću modela za generisanje sintetičkih slika.
Proširivanje skupa podataka navedenim metodama i dalje ne rešava dovoljno dobro problem male količine podataka.
U radu je opisana i tehnika učenja sa prenosom znanja \cite{zhuang2020comprehensive} na već obučenom modelu za detekciju objekta \cite{bochkovskiy2020yolov4}. Korišćenje učenja sa prenosom znanja za cilj ima da se upotrebi naučeno znanje iz jednog domena kako bi se bolje učilo u drugom \cite{bengio2012deep}. Indirektan doprinos korišćenja učenja sa prenosom znanja je i smanjivanje procesorkse snage potrebne za obuku modela.
Korišćenjem navedenih metoda proširivanja skupa podataka i učenja sa prenosom znanja, dobija se model sa boljim karakteristikama.

Ideje koje su ovde predstavljene zasnivaju se na prethodnim istraživanjima. Kod nekih istraživanja gde su na raspolaganju bile male količine podataka, pomoću standardnih transformacija slika, generisane su nove slike koje su korišćene u obuci modela i koje su pozitivno uticale na krajnje rezultate  \cite{brigato2021close}. Pored toga, predloženo je i generisanje novih slika generativnim suparničkim mrežama za proširenje skupa podataka radi povećanja performansi \cite{brigato2021close,liu2019generative}. Obuka generativnih suparničkih mreža sa malom količinom podataka ne daje zadovoljavajuće rezultate \cite{brigato2021close}, pa se pojavom metode diferencijabilne augmentacije za generativne suparničke mreže \cite{zhao2020differentiable} stvara mogućnost generisanja novih podataka pomoću malog skupa podataka. 
Cilj ovog rada je proširivanje skupa podataka standarnim transformacijama slika i generisanje sintetičkih podataka generativnim suparničkim mrežama sa malom količinom podataka, koje ranije nisu bile u fokusu i koje su postale dostupne metodom diferencijabilne augmentacije.

U glavi \ref{section2} je dat kratak pregled modela za detekciju objekata koji se koriste u ovom radu. U glavi \ref{section3} je dat pregled tehnika i generativne suparničke mreže koje se koriste u rešavanju problema male količine podataka, dok u glavi \ref{section4} se opisuju tehnike evaluacije tih modela. U glavi \ref{section5} su predstavljeni eksperimenti i rezultati dobijenih modela. U glavi \ref{section6} su ukratko prikazani problemi sa kojima se ovaj rad susreće, metode njihovog prevazilaženja i moguća dalja unapređenja rešenja.


% ------------------------------------------------------------------------------
\chapter{Detekcija objekata}
\label{section2}
% ------------------------------------------------------------------------------
Računarski vid (eng.~\textit{computer vision}) je oblast mašinskog učenja, koja se bavi izgradnjom i korišćenjem  sistema za obradu, analizu i interpretaciju digitalnih slika ili video zapisa \cite{ballard1982computer, huang1996computer}.
Detekcija objekata je tehnika računarskog vida, koja za zadatak ima 
da otkrije objekte na slici. Za uspešnu detekciju objekta potrebno je obučiti model na velikoj količini podataka. 
Kako je nekada nemoguće nabaviti dovoljnu količinu podatka, koristi se augmentacija podataka: podaci se proširuju dodavanjem modifikovanih ili sintetički generisanih podataka \cite{shorten2019survey}. 


% #######################################
\section{Razvojni put detekcije objekata}
\label{section2_detekcijaobjekta}
% #######################################


Detekcija objekata se koristi u velikom broju aplikacija, kao što su, na primer, autonomna vožnja, robotski vid, video nadzor, itd \cite{zou2019object}. U poslednje dve decenije, napredak u detekciji objekata je prošao kroz dva perioda \cite{zou2019object}: "tradicionalni period detekcije objekata" (pre 2014.~godine), i "period detekcije objekata zasnovan na dubokom učenju (eng.~\textit{deep learning})" (posle 2014.~godine).


Učinak detekcije objekata je značajno poboljšan zahvaljujući dubokoj konvolutivnoj neuronskoj mreži (eng.~\textit{convolutional neural networks, CNN}), što je dovelo do izuzetnih otkrića.
Razvoj duboke konvolutivne neuronske mreže takođe je omogućio otkrivanje graničnih okvira\footnote{Granični okviri predstavljaju koordinate na delu ili celoj slici u okviru kojih se nalazi prepoznati objekat.} i značajnih delova objekta na slikama \cite{girshick2014rich, ren2015faster, kang2017t, amit2020object}.


U eri dubokog učenja, detekcija objekata se može grupisati u dva tipa: \textit{dvostepena detekcija} i \textit{jednostepena detekcija}  \cite{zou2019object}.

U okviru dvostepene detekcije, prva faza modela se koristi za izdvajanje regiona\footnote{Regioni predstavljaju delove slike koji mogu da sadrže objekte ili delove objekata}, dok se druga koristi za klasifikaciju i dalje preciziranje objekata. Ovakav metod detekcije objekata je relativno spor, ali daje veoma precizne rezultate.

Modeli jednostepene detekcije objekata odnose se na klasu modela koji preskaču fazu predloga regiona. Ovakvi modeli zahtevaju samo jedan prolaz kroz neuronsku mrežu i predviđaju sve granične okvire u jednom prolazu na kraju. Ovaj tip modela obično ima bržu detekciju, ali manje je precizan pri otkrivanju i prepoznavanju objekata.


% #######################################
\section{Model za klasifikaciju objekata VGG16}
% #######################################

Model VGG16 koristi CNN i smatrao se jednim od najboljih modela računarskog vida 2014. godine nakon pobede na takmičenju ILSVR (Imagenet) \cite{simonyan2014very}. Autori ovog modela su posmatrali druge modele i zapazili da povećanjem dubine i koristeći arhitekturu sa manjim konvolutivnim filterima, može doći do poboljšanja performansi. Promena arhitekture se pokazala kao značajno poboljšanje u odnosu na prethodne modele \cite{simonyan2014very}. 

Model VGG16 spada u model jednostepene detekcije i dobio je svoj naziv po šesnaest slojeva koji mogu da uče, dok se celokupna mreža sastoji od trinaest konvolutivnih slojeva, pet slojeva agregacije (eng.~\textit{max pooling}) i tri duboko povezana sloja koji se sumiraju u ukupno dvadeset i jedan sloj. Arhitektura modela VGG16 je data na slici \ref{fig:section2_vgg16}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava2/vgg16_2.png}
    \caption{VGG16 arhitektura}
    \label{fig:section2_vgg16}
\end{figure}

U skupu podataka za ILSVR, test skup je sadržao oko četrdeset hiljada slika, što je bilo oko 10\% celokupnog skupa podataka \cite{LSVRC2013}.  Model je bio u mogućnosti da predvidi objekte na datim slikama sa greškom klasifikacije koja je iznosila 6.8\% na skupu za test i time je nadmašio prvi naredni model za 0,9\% \cite{simonyan2014very}.
Nedostatak modela VGG16 je da nije u mogućnosti da odredi okvire detektovanog objekta na slici.



% #######################################
\section{Model za detekciju objekata R-CNN}
% #######################################

Zbog ponovne upotrebe konvolutivnih neuronskih mreža i veće računarske snage na raspolaganju, 2014. godine pojavljuje se model pod nazivom regioni sa CNN karakteristikama (eng.~\textit{regions with CNN features, (R-CNN)}) \cite{girshick2014rich}. 
Model R-CNN je prvi model dvostepene detekcije i sastoji se od tri modula koji obavljaju različite zadatke \cite{girshick2014rich}:
\begin{enumerate}
  \item Prvi modul generiše predloge regiona pomoću algoritma selektivne pretrage. Algoritam selektivne pretrage vrši segmentaciju slike na osnovu intenziteta piksela koristeći metod segmentacije zasnovan na grafu \cite{narayan2008image}. Na osnovu dobijene mape segmentacije stvaraju se predlozi regiona koji se koriste u sledećem modulu \cite{uijlings2013selective}.
  \item Drugi modul je velika konvolutivna neuronska mreža. Svaki predlog se skalira na sliku fiksne veličine i unosi u obučeni CNN model za izdvajanje vektora karakteristika fiksne dužine.
  \item Treći modul je skup linearnih metoda potpornih vektora (eng.~\textit{support vector machines, (SVM)}) specifičnih za svaku klasu, koji vrše prepoznavanje objekata iz vektora karakteristika.
\end{enumerate}


Problemi koji se javljaju kod R-CNN-a su \cite{gandhi_2018}:
\begin{itemize}
    \item Zbog moguće klasifikacije velikog broja predloga regiona po slici, predviđanja modela nije moguće koristiti u realnom vremenu.
    \item Algoritam selektivne pretrage je fiksiran i kao takav se ne prilagođava podacima. To može da ima za posledicu da se u nekim situacijama dobijaju loši predlozi regiona.
\end{itemize}

Tokom nekoliko iteracija razvoja R-CNN-a dolazi do znatnog ubrzavanje modela i time nastaju novi modeli brz R-CNN (eng.~\textit{fast R-CNN}) \cite{girshick2015fast} i brži R-CNN (eng.~\textit{faster R-CNN}) \cite{ren2015faster}.  Model za detekciju objekata brz R-CNN ima sličan pristup kao R-CNN uz nekoliko jednostavnih poboljšanja modela. Model za detekciju objekata brži R-CNN  je sastavljena od dva modula. Prvi modul je duboko povezana konvolutivna mreža koja predlaže regione, dok je drugi modul model R-CNN koji koristi predložene regione za prepoznavanje objekata. Ceo sistem je jedinstvena, ujedinjena mreža za detekciju objekata \cite{ren2015faster}.


% #######################################
\section{Model za detekciju objekata YOLO}
% #######################################
%YOLO
Model za detekciju objekata R-CNN koristi regione da otkrije objekte unutar slike. Model ne gleda na kompletnu sliku, već umesto toga, gleda delove slike koji imaju visoku verovatnoću da sadrže objekte. YOLO (eng.~\textit{you only look once}) je model za otkrivanje objekata koji se razlikuje od modela zasnovanih na regionima. Model YOLO spada u model zasnovan na jednostepenoj detekciji i nastao je 2015.~godine \cite{redmon2016you}. Kod modela YOLO jedna konvolutivna mreža predviđa granične okvire i otkriva objekte.

Odvojene komponente detekcije objekata objedinjuju se u jednu neuronsku mrežu. Model koristi pronađene karakteristike iz cele slike da predvidi svaki granični okvir. Takođe, predviđaju se svi granični okviri za sve objekte na slici istovremeno. To znači da model globalno razmišlja o celokupnoj slici i svim objektima na njoj \cite{redmon2016you}. Model YOLO je duplo brži od modela brži R-CNN, i ima 5\% bolju preciznost pri detekciji objekata. Modelu YOLO je potrebno 12 milisekundi da uspešno predvidi objekte na slici, dok modelu brži R-CNN je potrebno 25 milisekundi da predvidi objekte. Poređenje modela je prikazano na slici \ref{fig:section2_YOLOvsRCNN} \cite{bdcc6030072}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{matfmaster/glava2/yolo4_rcnn.png}
    \caption{ Poređenje modela YOLO sa modelom brži R-CNN \cite{bdcc6030072}. Na $y$ osi je prikazana metrika srednje prosečne preciznosti koju modeli ostvaruju, dok $x$ osa predstavlja broj slika koji modeli mogu da obrade u sekundi.}
    \label{fig:section2_YOLOvsRCNN}
\end{figure}

% ------------------------------------------------------------------------------
\chapter{Tehnike proširivanja skupa podataka}
\label{section3}
% ------------------------------------------------------------------------------

Skup podataka je moguće proširiti kreiranjem novih podataka. U tehnike za kreiranje podataka spadaju augmentacija podataka i generativne suparničke mreže. U nekim slučajevima i nakon proširenja skupa za obuku, količina podataka koja je na raspolaganju može da bude nedovoljna za obuku modela. Takav problem se može ublažiti korišćenjem učenja sa prenosom znanja. 

% Detaljno poređenje modela koji je koristio tehnike proširivanja skupa podataka CIFAR-10 može se naći u radu \cite{brigato2021close}.


% #######################################
\section{Problem malog skupa podataka}
% #######################################

Modeli obučeni na malom skupu podataka obično uočavaju karakteristike koje su svojstvene tom malom skupu, ali ne i celoj populaciji podataka. To rezultira velikom varijansom i velikom greškom na skupu za test. U ovom radu koriste se dve metode kako bi se izbeglo ovakvo ponašanje. Prvi metod je proširivanje skupa podataka.
Podaci se proširuju slikama koje su izmenjene standardnim transformacijama i slikama koje su sintetički generisane pomoću generativnih suparničkih mreža.
Drugi metod predstavlja korišćenje učenja sa prenosom znanja.


% #######################################
\section{Standardne transformacije slika koje se koriste za augmentaciju}
\label{section3_increasedata_bas}
% #######################################
U standardne transformacije spadaju rotacija (eng.~\textit{rotation}), refleksija (eng.~\textit{flip}), skaliranje (eng.~\textit{scale}), seckanje (eng.~\textit{crop}), zamućenje (eng.~\textit{blur}) i augmentacija boja (eng.~\textit{color augmentation}).
Nasumičnim kombinovanjem navedenih metoda se kreiraju novi podaci koji služe kao proširenje skupa podataka za obučavanje. 

\subsection{Refleksija}
Refleksija slike se odnosi na kreiranje nove slike koja odgovara slici u ogledalu, u odnosu na vertikalnu ili horizontalnu osu. Operaciju refleksije nije moguće primeniti u svakom domenu. Na primer, vertikalna refleksija neće imati mnogo smisla u slučaju saobraćajnih vozila. Primeri refleksije su prikazani na slici \ref{fig:section3_flip}. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/flip.jpg}
    \caption{Primer refleksije: originalna slika (levo), vertikalna refleksija (sredina) i horizontalna refleksija (desno) \cite{unsplashOrange}}
    \label{fig:section3_flip}
\end{figure}

\subsection{Rotacija}
Rotacija predstavlja transformaciju koja kreira nove slike koje odgovaraju originalnoj slici okrenutoj za proizvoljan ugao. Primenom operacije rotacije dimenzije slike se često menjaju. Ukoliko je neophodno sačuvati originalne dimenzije, slika se po potrebi seče, dok se prazni delovi slike popunjavaju određenom metodom. Primeri rotacija su dati na slici \ref{fig:section3_rot}. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/rotate.jpg}
    \caption{Primer rotacije: originalna slika (levo), rotacija za 45\(^\circ\) (sredina) i  rotacija za 120\(^\circ\) (desno) \cite{unsplashOrange}}
    \label{fig:section3_rot}
\end{figure}

\subsection{Skaliranje}
Skaliranje predstavlja transformaciju koja povećava ili smanjuje sliku za zadati faktor koji je veći od nule. Prilikom korišćenja faktora skaliranja većeg od jedan, dimenzije konačne slike su veće od originalne. Da bi se sačuvala originalna dimenzija, nova slika se seče na originalnu dimenziju. U slučaju da je faktor skaliranja između nule i jedinice, dimenzije slike su manje od originalnih. Da bi se sačuvale originalne dimenzije, prazan prostor se popunjava određenom metodom. Primeri skaliranja su dati na slici \ref{fig:section3_scale}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/scale.jpg}
    \caption{Primer skaliranja: originalna slika (levo), faktor skaliranja veći od 1 (sredina) i faktor skaliranja između 0 i 1 (desno) \cite{unsplashOrange}}
    \label{fig:section3_scale}
\end{figure}


\subsection{Isecanje}
Isecanje slike se odnosi na kreiranje nove slike nasumičnim uzorkovanjem dela originalne slike. Isečak se potom skalira na dimenzije originalne slike. Primer isecanja je dat na slici \ref{fig:section3_cut}.
 
\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/crop.jpg}
    \caption{Primer isecanja: originalna slika (levo), nasumično isecanje (sredina i desno) \cite{unsplashOrange}}
    \label{fig:section3_cut}
\end{figure}

\subsection{Translacija}
Translacija podrazumeva pomeranje slike u horizontalnom ili vertikalnom pravcu. Ovaj metod je veoma koristan, jer se većina objekata može nalaziti na bilo kom mestu na slici. Prazan prostor koji nastaje nakon translacije se boji odgovarajućim metodama. Primer translacije je prikazan na slici \ref{fig:section3_trans}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/translate.jpg}
    \caption{Primer translacije: originalna slika (levo), nasumična translacija (sredina i desno) \cite{unsplashOrange}}
    \label{fig:section3_trans}
\end{figure}

\subsection{Gausov šum}
Gausov šum predstavlja dodavanje nasumičnih vrednosti iz normalne raspodele na piksele originalne slike. Time se dobija nova slika sa šumom. Dodavanjem Gausovog šuma, deformišu se sve karakteristike u podacima. To je bitno jer u skupu podataka za obučavanje mogu postojati podaci koji sadrže slične karakteristike, što može dovesti do preprilagođavanja modela koji se obučava na tom skupu. Primer šuma je dat na slici \ref{fig:section3_noise}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/noise.jpg}
    \caption{Primer dodavanja šuma:  originalna slika (levo), srednja vrednost 1 i standardna devijacija 0.1 (sredina), srednja vrednonst 0 i standardna devijacija 0.5 (desno) \cite{unsplashOrange}}
    \label{fig:section3_noise}
\end{figure}

\subsection{Gausovo zamućenje}
Gausovo zamućenje slike predstavlja primenu operacije konvolucije\footnote{konvolucija je operacija nad dve funkcije \(f\) i \(g\) koja proizvodi treću funkciju \(f*g\), koja izražava kako se oblik jedne modifikuje od strane druge} sa Gausovim zvonom \cite{ni2019}.
Povećanjem standardne devijacije dobija se jači efekat zamućenosti. Primer zamućenja je prikazan na slici \ref{fig:section3_blur}.


\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/blur.jpg}
    \caption{Primer zamućenja: originalna slika (levo), standardna devijacija 7 (sredina), standardna devijacija 21 (desno) \cite{unsplashOrange}} 
    \label{fig:section3_blur}
\end{figure}


\subsection{Augmentacija boja}

Augmentacija boja (eng.~\textit{color augmentation}) menja svojstava boje slike izmenom vrednosti njenih piksela. Vrednosti piksela mogu se menjati na različite načine.

Tehnika osvetljenja (eng.~\textit{brightness}) podrazumeva množenje svakog piksela slike odgovarajućom faktorom osvetljenja većim od nule. Ako je faktor osvetljenja između nule i jedinice, dobija se tamnija slika, a ako je veći od jedinice dobija se svetlija slika. Primer osvetljenja je prikazan na slici \ref{fig:section3_brightness}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/brightness.jpg}
    \caption{Primer menjanja osvetljenja, originalna slika (levo), faktor osvetljenja između 0 i 1 (sredina), faktor osvetljenja veći od 1 (desno) \cite{unsplashOrange}} 
    \label{fig:section3_brightness}
\end{figure}


Tehnika menjanja kontrasta (eng.~\textit{contrast}) predstavlja menjanje stepena razlike između svetlijih i tamnijih delova slike. Povećanjem kontrasta se povećava razlika između svetlijih i tamnijih delova, dok smanjivanjem razlika se umanjuje. Primer promene kontrasta je prikazan na slici \ref{fig:section3_contrast}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/contrast.jpg}
    \caption{Primer promene kontrasta, originalna slika (levo), primer pojačanih kontrasta (sredina i desno) \cite{unsplashOrange}} 
    \label{fig:section3_contrast}
\end{figure}


Tehnika menjanja intenziteta (eng.~\textit{saturation}) slike predstavlja menjanje jačine boja. Povećavanjem intenziteta se dobija slika sa izraženijim bojama. Primer promene intenziteta je prikazan na slici \ref{fig:section3_saturation}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/saturation.jpg}
    \caption{Primer promene intenziteta, originalna slika (levo), slabije povećanje intenziteta (sredina), jače povećanje intenziteta (desno) \cite{unsplashOrange}} 
    \label{fig:section3_saturation}
\end{figure}

Tehnika menjanja nijanse (eng.~\textit{HUE}) pomera piksele na slici u drugu tačku na krugu boja. Nasumično pomeranje generiše nove slike sa drugim bojama. Primer promene nijanse je prikazan na slici \ref{fig:section3_hue}.


\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava3/hue.jpg}
    \caption{Primer promene nijanse, originalna slika (levo), pomereni pikseli za nasumične vrednosti (sredina i desno) \cite{unsplashOrange}} 
    \label{fig:section3_hue}
\end{figure}

% #######################################
\section{Generativne suparničke mreže}
\label{section3_increasedata_gan}
% #######################################

Tokom razvoja mašinskog učenja, razvijen je koncept generativnih suparničkih mreža (eng.~\textit{generative adversarial network, GAN}). Kod generativnih suparničkih mreža postoje dva modela: \textit{generator} i \textit{diskriminator}. Generator za zadatak ima da generiše slike, a diskriminator da razlikuje slike generisane generatorom od pravih slika \cite{goodfellow2014generative}.
Osnovna arhitektura generativnih suparničkih mreža je prikazana na slici \ref{fig:section2_gans}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava2/gans_cus.png}
    \caption{Generativne suparničke mreže: ulazni podaci predstavljaju slike, G(z) je  slika generisa od strane generatora \cite{gans_image}}
    \label{fig:section2_gans}
\end{figure}

Generativne suparničke mreže se u velikoj meri oslanjaju na velike količine raznovrsnih i visokokvalitetnih podataka za obučavanje, kako bi generisali fotorealistične slike \cite{zhao2020differentiable}. 
Generator se obučava da što bolje generiše slike koje diskriminator neće razlikovati od stvarnih, dok diskriminator se obučava da što bolje razlikuje lažne slike od stvarnih. Kako se generator menja, mora i diskriminator i obratno. Tako se generator i diskriminator obučavaju naizmenično \cite{ml2019}. 
Funkcije grešaka za generativne suparničke mreže mogu se formulisati preko igre nulte sume \cite{goodfellow2020generative, hodgson2006microeconomics}. Generator pokušava da minimizuje funkciju dok diskriminator pokušava da maksimizuje. Za dati generator $G$ i diskriminator $D$ problem igre nulte sume se definiše kao \cite{goodfellow2020generative, ml2019}:

\begin{equation}
   \min_{G}\max_{D}\mathbb{E}_{x}[\log{D(x)}] +  \mathbb{E}_{z}[1 - \log{D(G(z))}]
\end{equation}
U datoj formuli:
\begin{itemize}
    \item $D(x)$ predstavlja procenu diskriminatora da je pravi podatak $x$ stvaran,
    \item $\mathbb{E}_{x}$ je očekivanje po raspodeli stvarnih podataka,
    \item $G(z)$ je izlaz generatora za vrednost $z$ iz latentnog prostora,
    \item $D(G(z))$ predstavlja procenu diskriminatora da je lažni podatak stvaran,
    \item $\mathbb{E}_{z}$ je očekivanje po raspodeli podataka u latentnom prostoru.
\end{itemize}


Progresivne generativne suparničke mreže (eng.~\textit{progressive generative adversarial network}) modifikuju arhitekturu na taj način da obučavanje generativnih suparničkih mreža počinje sa niskom rezolucijom slike, a zatim progresivno povećava rezoluciju dodavanjem slojeva u mrežu. Proces obuke je prikazan na slici \ref{fig:section2_augmentation_progressivegans}.
Ovakva inkrementalna priroda omogućava da model tokom obuke prvo otkrije vizuelne karakteristike koje se manifestuju na početnim slojevima, od grubih crta pa do sitnih detalja \cite{karras2017progressive}.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{matfmaster/glava2/progressive_gan.png}
    \caption{Proces obuke progresivnih generativnih suparničkih mreža počinje od slika niske rezolucije (4\(\times\)4) i progresivno se dodaju slojevi u mrežu i rezolucija povećava do (1024\(\times\)1024). Prva slika (slika a) predstavlja prvu iteraciju obuke modela, druga slika (slika b) predstavlja drugu iteraciju obuke, dok treća slika (slika c) predstavlja poslednju iteraciju. Slike automobila (slika d) predstavljaju generisane slike sa najvećom rezolucijom \cite{karras2017progressive}. }
    \label{fig:section2_augmentation_progressivegans}
\end{figure}

\clearpage
Tokom razvijanja generativnih suparničkih mreža najviše se radilo na poboljšanju diskriminatora, što je vodilo ka boljim rezultatima. S druge strane, \textit{StyleGAN} (eng.~\textit{style generative adversarial network}) je dodatak arhitekturi generativnih suparničkih mreža, koji uvodi značajne modifikacije u model generatora \cite{karras2019style}. 

Generator modela zasnovan na stilu se sastoji iz dva dela i prikazan je na slici \ref{fig:section2_augmentation_stylegan}. 
Prvi deo čini duboko povezanu mrežu sa osam slojeva. Mreža je predstavljena kao funkcija \(f: Z\to W\) i naziva se mreža preslikavanja (eng.~\textit{mapping network}). Ulaz mreže predstavlja normalizovani latentni kod \(z \in Z\). Latentni kod (eng.~\textit{latent code}) ili z-vektor \(z\), je vektor koji sadrži slučajne vrednosti iz Gausove raspodele. Prostor u kome se nalaze svi z-vektori se naziva Z-prostor (eng.~\textit{Z-space}) i obeležava se sa \(Z\). Kao izlaz mreže se dobija vektor \(w\) koji pripada latentnom prostoru \(W\). Latentni prostor (eng.~\textit{latent space}) je apstraktni višedimenzionalni prostor koji sadrži vrednosti karakteristika koje se ne mogu direktno interpretirati.
Drugi deo generatora predstavlja mrežu koja uz pomoć vektora sa nasumičnim vrednostima iz Gausove raspodele, slučajnog šuma i vektora \(w\) transformisanog afinim transformacijama generiše sliku. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{matfmaster/glava2/stylegan_cus3.png}
    \caption{Model generatora zasnovanog na stilu, "A" predstavlja afine transformacije dok "B" predstavlja faktor skaliranja za šum \cite{karras2019style}. }
    \label{fig:section2_augmentation_stylegan}
\end{figure}


\clearpage
Vektor \(w\) transformisan afinim transformacijama služi za prilagođavanje stila sintetički generisanim slikama pomoću adaptivne normalizacije instance (eng.~\textit{adaptive instance normalization, AdaIN}). Stil slike predstavlja vektor u latentnom prostoru koji je razdvojen od vektora semantičkog sadržaja slike \cite{huang2017arbitrary}. Primer prenosa stila sa jedne slike na drugu je dat na slici \ref{fig:section2_augmentation_adain}.


\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava2/adain_cus.png}
    \caption{Prenos stilova na željene slike i rezultati operacije AdaIN \cite{huang2017arbitrary}. }
    \label{fig:section2_augmentation_adain}
\end{figure}


Model \textit{StyleGAN} generiše fotorealistične slike. Tokom razvoja, model \textit{StyleGAN} je prošao kroz fazu optimizacije i manje izmene mreže sinteze. Nova verzija \textit{StyleGAN}-a, \textit{StyleGAN2} donosi i do 60\% brže obučavanje modela u odnosu na prvu verziju \cite{karras2020analyzing}. Zbog ovakvih ubrzanja, direktno se smanjuje procesorska snaga potrebna za obučavanje. U radu se koristi ova poboljšana verzija, tačnije arhitektura \textit{StyleGAN2}.

Ukoliko ne postoji na raspolaganju velika količina podataka, rad sa generativnim suparničkim mrežama može da rezultira nekvalitetnim modelima.
Da bi se takav problem ublažio, uvedena je metoda diferencijabilne augmentacije (eng.~\textit{differentiable augmentation}) za model \textit{StyleGAN2}. Metoda koristi različite tipove augmentacija nad stvarnim i lažnim podacima. Metoda omogućava stabilnije obučavanje i dovodi do bolje konvergencije u odnosu na obučavanje modela bez metode diferencijabilne augmentacije nad istim skupom podataka. Model \textit{StyleGAN2} sa metodom diferencijabilne augmentacija je u stanju da proizvede realistične slike, čak i nad skupom podataka koji sadrži samo sto slika \cite{zhao2020differentiable}.


% #######################################
\section{Učenje sa prenosom znanja}
\label{section3_trasnferucenje}
% #######################################
U nadgledanom učenju, modeli se obučavaju da nauče odnose koji važe između datih ulaza i izlaza. Modeli zatim mogu da vrše predviđanja izlaza nad novim podacima. Modeli će na ovaj način davati dobre rezultate kada rešavaju problem koji se nalazi u istom domenu kao i podaci za obučavanje. Rezultat će se pogoršati ako se domen problema promeni. U najgorem slučaju, može da bude potrebno obučavati novi model čak i kada su domeni problema slični \cite{zhuang2020comprehensive}.

Učenje sa prenosom znanja predstavlja oblast mašinskog učenja koja se bavi iskorišćavanjem znanja iz postojećeg obučenog modela pri obučavanju novog modela koji treba da rešava sličan zadatak. Tehnika se najčešće koristi kada za obuku novog modela nije na raspolaganju dovoljna količina podataka ili resursa. Korišćenje učenja sa prenosom znanja donosi niz prednosti od kojih su glavne ušteda resursa, smanjivanje greške tokom obuke i generalizacija modela \cite{zhuang2020comprehensive}.




% #######################################
\chapter{Tehnike evaluacije modela}
\label{section4}
% #######################################
Za evaluaciju modela kod detekcije objekata koristi se mera srednje prosečne preciznosti (eng.~\textit{mean average precission, mAP}), koja uzima u obzir preciznost (eng.~\textit{precision}) i odziv (eng.~\textit{recall}). Takođe, koristi se i matrica konfuzije, kod koje računanje ispravno i pogrešno klasifikovanih objekta zavisi od zadatog praga metrike preseka po uniji (eng.~\textit{intersection over union, IoU}) i ocene pouzdanosti (eng.~\textit{confidence score}) klasifikovanih objekata. Ocena pouzdanosti predstavlja vrednost verovatnoće objekta koju joj je model dodelio prilikom klasifikacije.


% +++++++++++++++++++++++++++++++
\section{Presek po uniji}
% +++++++++++++++++++++++++++++++
Presek po uniji predstavlja metriku evaluacije koja se koristi za merenje tačnosti detektora objekata. Na slici \ref{fig:section3_iou} dat je primer okvira, gde je predviđen okvir nacrtan crvenom bojom, dok je pravi okvir nacrtan žutom bojom. Metrika se računa tako što se presek dva okvira podeli njihovom unijom (slika \ref{fig:section3_iou_calc}). Na savršeno predviđene granične okvire metrika IoU će davati vrednost 1.0, dok u slučaju da se granični okviri ne seku vrednost će biti 0. Idealni slučajevi da je metrika 1.0 su retki, i u praksi se smatra dobrim rezultatom kada IoU ima za vrednost 0.8.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{matfmaster/glava3/iou_cus.png}
    \caption{Predviđen okvir (crveno) i pravi okvir (žuto) nad zadatim objektom}
    \label{fig:section3_iou}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{matfmaster/glava3/iou_calc_cus.png}
    \caption{Demonstracija računanja IoU metrike}
    \label{fig:section3_iou_calc}
\end{figure}



% +++++++++++++++++++++++++++++++
\section{Matrica konfuzije za detekciju objekata}
% +++++++++++++++++++++++++++++++

Matrica konfuzije je tabelarni prikaz brojeva ispravno i pogrešno klasifikovanih objekata na osnovu kojih se mogu vršiti ocene modela klasifikacije. Za višeklasnu klasifikaciju detekcije objekata matrica konfuzije se proširuje jednom kolonom i vrstom. Nova kolona služi za zapis broja objekata koji su klasifikovani na slici, a na njoj se ne nalaze. Vrsta služi za zapis broja objekata koji se nalaze na slici, ali nisu klasifikovani.
Objekat se klasifikuje ispravno kada ispunjava sledeće uslove:
\begin{itemize}
    \item model je tačno klasifikovao objekat, tj. dodelio mu je pravu klasu,
    \item vrednost ocene pouzdanosti objekta prelazi zadati prag ocene pouzdanosti (obično se u praksi koristi 0.5) i 
    \item IoU vrednost objekta prelazi zadati IoU prag (obično se u praksi koristi 0.5)
\end{itemize}
U slučaju da objekat neispunjava jedan od datih uslova, klasifikuje se pogrešno. 

Matrica konfuzije se računa i za svaku klasu pojedinačno i slična je binarnoj klasifikaciji. Prilikom računanja matrice konfuzije, posmatra se jedna konkretna klasa i ta klasa se smatra pozitivnom, dok skup koji sadrži sve objekte ostalih klasa se smatra negativnom klasom.
Objekat se klasifikuje kao pozitivan ako ispunjava sledeće uslove:
\begin{itemize}
    \item objekat pripada pozitivnoj klasi model mu je dodelio pozitivnu klasu,
    \item IoU vrednost objekta prelazi zadati IoU prag
\end{itemize}
Ako objekat neispunjava jedan od datih uslova, onda mu se dodeljuje negativna klasa. Ocena pouzdanosti ne učestvuje u računanju matrice konfuzije za svaku klasu.

\textit{Stvarno pozitivni} (eng.~\textit{True Positive, TP}) je broj objekata koji pripadaju pozitivnoj klasi, model im je dodelio pozitivnu klasu i IoU vrednost svakog objekta prelazi zadati IoU prag.

\textit{Stvarno negativni} (eng.~\textit{True Negative, TN}) je broj objekata koji ne pripadaju pozitivnoj klasi i model im je dodelio negativnu klasu. IoU se ne upoređuje sa pragom.

\textit{Lažno pozitivni} (eng.~\textit{False Positive, FP}) je broj objekata koji pripadaju negativnoj klasi ali im je model dodelio pozitivnu klasu. Takođe, to je i broj objekata koji pripadaju pozitivnoj klasi ali IoU vrednost svakog objekta ne prelazi zadati IoU prag.

\textit{Lažno negativni} (eng.~\textit{False Negative, FN}) je broj objekata koji pripadaju pozitivnoj klasi a model im je dodelio negativnu klasu. IoU se ne upoređuje sa pragom jer je klasifikacija pogrešna. 

% +++++++++++++++++++++++++++++++
\section{Preciznost, odziv i \texorpdfstring{$F_1$}{TEXT}-mera}
% +++++++++++++++++++++++++++++++
Preciznost je procenat stvarno pozitivnih objekata među objektima koji su klasifikovani kao pozitivni i definiše se formulom:

\begin{equation}
    Precision = \frac{TP}{TP+FP}
\end{equation}
Veća preciznost takođe znači da postoji manji broj lažno pozitivnih objekata.

Odziv predstavlja procenat pozitivnih objekata koji su ispravno klasifikovani i definiše se formulom:

\begin{equation}
    Recall = \frac{TP}{TP+FN}
\end{equation}

Visok odziv znači da postoji mali broj lažno negativnih objekata.

Preciznost i odziv se mogu sumirati u meru, koja se zove $F_1$-mera (eng.~\textit{$F_1$-score}) \cite{sasaki2007truth} i definiše se formulom:
\begin{equation}
\label{eq:f1}
    F_1 = 2\frac{Precision \cdot Recall}{Precision+Recall}
\end{equation}
$F_1$-mera je harmonična sredina preciznosti i odziva i ona daje relativno niske ocene kada su preciznost ili odziv niski. 

Srednja $F_1$-mera ili (eng.~\textit{macro-averaged $F_1$-score}) računa se kao aritmetička sredina:
\begin{equation}
\label{eq:f1a}
    F_{1avg} = \frac{1}{n}\sum_{k=0}^{k=n-1} F_{1k}
\end{equation}
gde je \(F_{1k}\) vrednost $F_1$-mere za \(k\)-tu klasu. Srednja $F_1$-mera se izračunava korišćenjem aritmetičke sredine svih $F_1$-mera za svaku klasu i koristi se za procenu kvaliteta sa više klasa.

Srednja težinska $F_1$-mera se računa sledećom formulom:
\begin{equation}
\label{eq:f1wa}
    F_{1wavg} = \sum_{k=0}^{k=n-1} (F_{1k} S_{k})
\end{equation}
gde su \(F_{1k}\) i \(S_{k}\) vrednost $F_1$-mere za \(k\)-tu klasu i proporcijalan broj instanci \(k\)-te klase u odnosu na ukupn broj instanci u skupu podataka.

% +++++++++++++++++++++++++++++++
\section{Srednja prosečna preciznost}
\label{section4_avgprecision}
% +++++++++++++++++++++++++++++++

Prosečna preciznost (eng.~\textit{average precision}) je način računanja površine ispod krive preciznosti i odziva za jednu klasu. Vrednosti preciznosti i odziva se računaju za zadate vrednosti IoU pragova iz intervala [0.5 do 1.0), najčešće sa korakom 0.05.
Niz izračunatih vrednosti odziva i preciznost se dopunjuje sa \textbf{0} i \textbf{1}, respektivno. 

Prosečna preciznost se računa sledećom formulom:
\begin{equation}
\label{eq:ap}
    AP = \sum_{k=0}^{k=n-1} (R_{k} - R_{k+1})P_{k}
\end{equation}
gde su \(R_{k}\) i \(P_{k}\) odziv i prezicnost za \(k\)-ti IoU prag.
Srednja prosečna preciznost se računa kao srednja vrednost svih prosečnih preciznosti koja je data formulom:
\begin{equation}
\label{eq:map}
    mAP =\frac{1}{N} \sum_{i=1}^{N} AP_{i}
\end{equation}
gde \(N\) predstavlja broj klasa, a \(AP_{i}\) prosečnu preciznost za klasu 
\(i\).

% +++++++++++++++++++++++++++++++
\section{Fréchet-ova udaljenost}
% +++++++++++++++++++++++++++++++

Fréchet-ova udaljenost (eng.~\textit{Fréchet inception distance, FID}) je metrika koja se koristi za procenu kvaliteta slika koje su generisane od strane generativnih suparničkih mreža \cite{heusel2017gans}. Fréchet-ova udaljenost upoređuje distribuciju generisanih slika sa distribucijom stvarnih slika koje su korišćene za obuku generatora. Fréchet-ova udaljenost za dve iste slike daje vrednost nula, dok za različite daje broj koji je veći od nule.  

Fréchet-ova udaljenost se računa za dve zajedničke normalne raspodele \(\mathcal{N}(\mu,\Sigma)\) i \(\mathcal{N}(\mu',\Sigma')\) sledećom formulom \cite{dowson1982frechet, heusel2017gans}:
\begin{equation}
    d_{F}(\mathcal N(\mu, \Sigma), \mathcal N(\mu', \Sigma'))^2 =
        \| \mu - \mu' \|^{2}_{2} + 
        tr\left(\Sigma + \Sigma' -
        2\left(\Sigma^\frac{1}{2} \cdot \Sigma' \cdot \Sigma^\frac{1}{2} \right)^\frac{1}{2} \right)
\end{equation}

U praktičnoj upotrebi, distribucije slika se dobijaju računanjem srednjih vrednosti (\(\mu\), \(\mu'\)) i matrica kovarijansi (\(\Sigma\),\(\Sigma'\)) pomoću vektora dobijenih modelom \textit{InceptionV3}\footnote{InceptionV3 je konvolutivna neuronska mreža koja se koristi za analizu slika i detekciju objekata.}.


% ------------------------------------------------------------------------------
\clearpage
\chapter{Implementacija i rezultati}
\label{section5}
% ------------------------------------------------------------------------------

U okviru implementacije, dostupan skup podataka se proširuje metodama augmentacije i sintetičkim podacima koje generiše model \textit{StlyeGAN2}.
Da bi se ocenilo da li primenjene tehnike omogućavaju poboljšanje, vrši se i obučavanje modela na osnovnom skupu podataka i njegovo poređenje sa modelima koji su obučeni na proširenom skupu podataka.
Kod koji je razvijen u okviru rada na tezi je dostupan na adresi  \underline{\href{https://github.com/Grula/vehicle-detection}{\textit{github}-a}}\footnote{https://github.com/Grula/vehicle-detection} \cite{vehicleGit2022}. Podaci koji su korišćeni u ovom radu, kao i generisani podaci, dostupni su na \href{https://drive.google.com/file/d/1EkrO28-iBCVWyPqy5mJXn8P8EoKQ6xUH/view?usp=sharing}{\underline{ovoj adresi}}\footnote{https://drive.google.com/file/d/1EkrO28-iBCVWyPqy5mJXn8P8EoKQ6xUH/view?usp=sharing} \cite{vehicleData2022}. Za obuku modela korišćena je platforma \href{https://research.google.com/colaboratory/}{\underline{\textit{Google Colab}}}\footnote{https://research.google.com/colaboratory}. Platforma je obezbeđivala grafičku kartu NVIDIA Tesla P100-PCIE sa 16GB RAM memorije. 

% #######################################
\section{Dostupni podaci}
% #######################################

Institut BRAIN (eng.~\textit{Brazilian Atrifical Inteligence Nucleus}), u okviru fakulteta FACENS\footnote{(www.facens.br)} (pt.~\textit{Centro Universitário FACENS}, eng.~\textit{Faculty of Engineering of Sorocaba}) Sao Paulo, Brazil je obezbedio označeni skup podataka, pod nazivom \bvs{} (eng.~\textit{Brazilian vehicle set, BVS}), koji je korišćen u ovom radu. Skup podataka \bvs{} sadrži četiri klase: \textit{car}, \textit{motorbike}, \textit{truck} i \textit{bus}. Primeri iz ovih klasa su prikazani na slici \ref{fig:section3_allclasses}. Ukupna količina podataka iznosi 1872 slike, od kojih većina pripada klasama \textit{car} i \textit{motorbike}. U skupu podataka \bvs, rezolucija svih slika iznosi 800$\times$600px. 

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{matfmaster/glava3/car.jpg}
        \caption{\textit{car}}
        \label{fig:section3_car}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{matfmaster/glava3/bike.jpg}
        \caption{\textit{motorbike}}
        \label{fig:section3_motorbike}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{matfmaster/glava3/truck.jpg}
        \caption{\textit{truck}}
        \label{fig:section3_truck}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{matfmaster/glava3/bus.jpg}
        \caption{\textit{bus}}
        \label{fig:section3_bus}
    \end{subfigure}
    ~
    \caption{Primeri slika iz dostupnih klasa}\label{fig:section3_allclasses}
\end{figure}


\clearpage
Slike se dele u dva skupa, skup za obuku i skup za test modela. Nasumično je uzeto 10\% slika iz svake klase za test skup. Test skup nije učestvovao ni u jednoj tehnici augmentacije i nije korišćen ni na koji način pri štimovanju modela. Ukupan broj slika svake klase, broj slika koji pripadaju skupu za obuku i broj slika koji pripada test skupu je prikazan u tabeli \ref{tab:section4_dostpunipodaci}. Iz tabele \ref{tab:section4_dostpunipodaci} se vidi da je neizbalansiranost između klasa izuzetno visoka, čak 1:15 između klasa \textit{bus} i \textit{car}.

\begin{table}[htb]
    \begin{center}
    \caption{Ukupan broj slika za svaku klasu, i broj nakon podele u skup za obuku i u skup za test }\label{tab:section4_dostpunipodaci}
    \begin{tabular}{l|c|c|c}
    klasa & ukupan broj & skup za obuku & test skup\\ 
    \hline
    car & 889 & 800 & 89 \\
    motorbike & 966 & 869 & 97 \\
    truck & 10 & 9 & 1 \\
    bus & 7 & 6 & 1 \\
    \end{tabular}
    \end{center}
\end{table}


% #######################################################################
\section{Kreiranje sintetičkih podataka}
% #######################################################################

Skup za obučavanje je proširivan na dva načina: slike su generisane standardnim transformacijama za augmentaciju i modelom \textit{StyleGAN2}. U tabeli \ref{tab:section4_generisaneslike} je dat prikaz tačnog broja slika koji je generisan da bi se dobile izbalansirane klase, tačnije da svaka klasa sadrži podjednaki broj slika u skupu za obuku. 
Broj slika koji je izabran za proširivanje skupa za obuku je izabran na osnovu klase koja je sadržala najveću količinu podataka, tačnije klase \textit{motorbike}. Klasa \textit{motorbike} je proširena sa 869 slika, tačnije sa onoliko slika koliko je prisutno u skupu za obuku. Nakon proširenja skupa za obuku, svaka klasa sadrži po 1738 slika.

\begin{table}[h!]
    \begin{center}
    \caption{Ukupan broj generisanih slika}\label{tab:section4_generisaneslike}
    \begin{tabular}{c|c|c|c|c}
        \textit{klasa} & \textit{car} &  \textit{motorbike} &  \textit{truck} & \textit{bus} \\ 
        \hline
        broj generisanih slika & 938 & 869 & 1732 & 1729 \\ 
    \end{tabular}
    \end{center}
\end{table}

% +++++++++++++++++++++++++++++++
% \subsection{Generisanje podataka standardnim augmentacijama} IZMENA std aug (3.2-1)
\clearpage
\subsection{Generisanje podataka standardnim transformacijama slika}
% +++++++++++++++++++++++++++++++

Zbog potrebe proširivanja skupa podataka \bvs, generišu se novi podaci tehnikama augmentacije (poglavlje \ref{section3_increasedata_bas}). Prošireni skup se dalje u radu naziva \bvs{standard}.
Skup augmentacija koje se primenjuju su: 
\begin{itemize}
    \item refleksija --- vrši se samo u horizontalnom smeru i vodi se računa o promeni koordinata graničnih okvira, 
    \item rotacija --- vrši sa nasumičnim uglom između jednog i pet stepeni i prazan prostor se dopunjava bojama graničnih piksela,
    \item translacija ---  pomera sliku u nasumičnom smeru za deset piksela i prazan prostor se dopunjava bojama graničnih piksela,
    \item Gausov šum --- pikseli sa slike se preslikavaju u interval -1 do 1 i na njih se dodaje šum sa konstantnom standardnom devijacijom 0.1 i srednjom vrednošću 0. Nakon dodavanja šuma, pikseli se vraćaju u interval 0 do 255.
    \item Gausovo zamućenje --- primenjuje se na sliku sa konstantom standardnom devijacijom koja iznosi 7. Vrednost standardne devijacije je izabrana zbog rezolucije slika u skupu \bvs. Korišćenjem vrednosti 7 za standardnu devijaciju, slike se zamućuju dok je i dalje moguće prepoznati objekat na slici.
    \item augmentacija boja --- Parametar osvetljenja se nasumično bira iz uniformne raspodele iz intervala 0.5 do 1.5. Parametri kontrasta, intenziteta i nijanse se nasumično biraju iz uniformne raspodele iz intervala 0.0 do 10.0. Intervali augmentacija boja su izabrani nakon testiranja intervala različitih opsega. Zaključeno je da se najbolji rezultati dobijaju korišćenjem navedenih intervala.
\end{itemize}

\noindent Iz opisanog skupa augmentacija primenjuju se četiri nasumično izabrane augmentacije. Nasumično se bira jedna afina transformacija iz skupa koji čine refleksija, rotacija i translacija. Takođe, bira se jedna augmentacija između Gausovog zamućenja i Gausovog šuma. Iz skupa augmentacija boja koje čine osvetljenje, kontrast, intenzitet i nijansa, nasumično se biraju dve augmentacije. Primeri generisanih slika su prikazani na slici \ref{fig:basic_aug}.

\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/1.jpg}
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/2.jpg}
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/3.jpg}
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/4.jpg}  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/5.jpg}
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/6.jpg}
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/7.jpg}
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/8.jpg}
  \includegraphics[width=0.32\textwidth]{matfmaster/glava4/basic_aug/9.jpg}
\caption{Primeri slika generisanih standardnim transformacijama}\label{fig:basic_aug}
\end{figure}

 
% +++++++++++++++++++++++++++++++
\clearpage
\subsection{Generisanje podataka modelom \textit{StyleGAN2}}
% +++++++++++++++++++++++++++++++

Skup podataka \bvs{} se proširuje i sintetičkim podacima generisanim od strane modela \textit{StyleGAN2}. Za ovako proširen skup u radu se koristi naziv \bvs{style}. 

Međutim, problem male količine podataka se takođe javlja za generisanje novih slika modelom \textit{StyleGAN2}. Korišćenjem metode diferencijabilne augmentacije koja je navedena u poglavlju \ref{section3_increasedata_gan} prevazilazi se problem male količine podataka i model uspešno generiše slike. Implementirani metod diferencijabilne augmentacije je testiran nad skupom podataka CIFAR-10 \cite{2020diffaugment_report}.

Arhitektura modela \textit{StyleGAN2} je implementirana pomoću biblioteke \textit{Tensorflow} 2.0\footnote{Biblioteka \textit{Tensorflow} 2.0 je otvorenog koda i pruža sveobuhvatan ekosistem alata. Objavljena je 2015. godine, a objavio ju je tim \textit{Google Brain}. Osnovna namena je pravljenje modela mašinskog učenja. Biblioteka je namenjena za korišćenje u programskom jeziku \textit{Python}.}.
Generisane slike su dimenzija 512\(\times\)512. Odabrana je ta dimenzija zbog ograničenja memorije grafičke karte. Obuka modela je trajala dvanaest do četrdeset osam sati u zavisnosti od same klase. Na svakih šest sati obuke ili, tačnije, na dvadeset pet hiljada epoha, pravljena je tačka provere (eng.~\textit{checkpoint}). Nakon svake tačke provere generisane su slike za računanje Fréchet-ove udaljenosti.


Za evaluaciju modela \textit{StyleGAN2} koristila se metrika Fréchet-ove udaljenosti i funkcije grešaka za generativne suparničke mreže. Nakon svake tačke provere, pomoću Fréchet-ove udaljenosti procenjivana je sličnost između dva skupa slika: generisane slike pomoću modela poređene su sa pravim slikama iz test skupa \bvs. Računanje Fréchet-ova udaljenosti odvijalo se na grafičkoj karti NVIDIA 780Ti i trajala je ukupno deset minuta. Kada se na generisanoj slici mogao prepoznati objekat i kada se funkcija greške diskriminatora i generatora nije znatno smanjivala, dalja obuka modela je prekidana. Tačan broj epoha svake klase je dat dalje u tekstu.


%___________________
\subsubsection{Klase \textit{Bus} i \textit{Truck}}
%___________________

Obuka modela \textit{StyleGAN2}-a nad klasama \textit{truck} i \textit{bus} predstavljala je veliki izazov zbog male količine dostupnih podataka. 
Obuka modela je trajala dvadeset četiri sata. Za obuku modela je generisano dvesta hiljada slika pomoću metode diferencijabilne augmentacije. Originalan skup slika za obuku klase \textit{bus} je sadržao šest slika, a skup za obuku klase \textit{truck} je sadržao devet slika.


\clearpage
Za klasu \textit{truck} funkcija greške je data na slici \ref{fig:section4_stylegan_truck_loss} i rezultat Fréchet-ove udaljenosti za dve tačke provere je dat u tabeli \ref{tab:section4_fid_t}. Iz funkcije greške za diskriminator može se zapaziti da daljom obukom je moglo doći do poboljšanja diskriminatora. Povećanje funkcije greške diskriminatora znači da je generator počeo da generiše slike koje je diskriminatoru bilo teže da razlikuje od stvarnih. Sa slika generisanih poslednjim težinama modela, moguće je uočiti glavne karakteristike objekata. Kako se objekti na slici mogu prepoznati i zbog uštede resursa obuka se prekinula. Primeri generisanih slika klase \textit{truck} su prikazani na slici \ref{fig:section4_stylegan_truck_images}.


\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/truck/g_loss.png}
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/truck/d_loss.png}
\caption{Funkcije grešaka za klasu \textit{truck}, generator (levo) i diskriminator (desno). U oba slučaja, \textit{x} osa predstavlja epohe, dok \textit{y} osa predstavlja vrednosti odgovarajuće funkcije greške.}\label{fig:section4_stylegan_truck_loss}
\end{figure}



\begin{table}[!htb]
\caption{Klasa \textit{truck}}\label{tab:section4_fid_t}
\centering
    \begin{tabular}{c|c}
        broj epohe &  Fréchet-ova udaljenost \\
        \hline
        25 hiljada & 432.8 \\
        \hline
        50 hiljada & 188.5 \\
    \end{tabular}
\end{table}

\begin{figure}[!htbp]
\centering
    \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/truck/image0.png}
    \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/truck/image6.png}
\caption{Primeri generisanih slika klase \textit{truck}}
\label{fig:section4_stylegan_truck_images}
\end{figure}


\clearpage
Za klasu \textit{bus} iz funkcije greške (slika \ref{fig:section4_stylegan_bus_loss}) i rezultata Fréchet-ove udaljenosti (tabela \ref{tab:section4_fid_b}) može se zaključiti da se daljom obukom za narednih dvadeset pet hiljada epoha ne dobijaju znatno bolji rezultati. Primeri generisanih slika klase \textit{bus} su prikazani na slici \ref{fig:section4_stylegan_bus_images}.


\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/bus/g_loss.png}
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/bus/d_loss.png}
\caption{Funkcije grešaka za klasu \textit{bus}, generator (levo) i diskriminator (desno). U oba slučaja, \textit{x} osa predstavlja epohe, dok \textit{y} osa predstavlja vrednosti odgovarajuće funkcije greške.}\label{fig:section4_stylegan_bus_loss}
\end{figure}

\begin{table}[!htb]
\caption{Klasa \textit{bus}}\label{tab:section4_fid_b}
\centering
    \begin{tabular}{c|c}
        broj epohe &  Fréchet-ova udaljenost \\
        \hline
        25 hiljada & 369.2 \\
        \hline
        50 hiljada & 220.5 \\
    \end{tabular}
\end{table}


\begin{figure}[!htbp]
\centering
    \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/bus/image0.png}  \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/bus/image8.png} 
\caption{Primeri generisanih slika klase \textit{bus}}
\label{fig:section4_stylegan_bus_images}
\end{figure}

%___________________
\clearpage
\subsubsection{Klase \textit{car} i \textit{motorbike}}
%___________________

Obuka modela nad klasom \textit{car} je trajala oko trideset šest sati i metodom diferencijabilne augmentacije je generisano trista hiljada slika. Za klasu \textit{car}, funkcija greške je prikazana na slici \ref{fig:section4_stylegan_car_loss}. Rezultat Fréchet-ove udaljenosti je prikazan u tabeli \ref{tab:section4_fid_c}. Daljom obukom klase \textit{car} ne dobijaju se značajna poboljšanja modela.
Primeri generisanih slika klase \textit{car} su prikazani na slici \ref{fig:section4_stylegan_car_images}.

\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/car/g_loss.png}
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/car/d_loss.png}
\caption{Funkcije grešaka za klasu \textit{car}, generator (levo) i diskriminator (desno). U oba slučaja, \textit{x} osa predstavlja epohe, dok \textit{y} osa predstavlja vrednosti odgovarajuće funkcije greške.}\label{fig:section4_stylegan_car_loss}
\end{figure}


\begin{table}[!htb]
\caption{Klasa \textit{car}}\label{tab:section4_fid_c}
\centering
    \begin{tabular}{c|c}
        broj epohe &  Fréchet-ova udaljenost \\
        \hline
        25 hiljada & 107.6 \\
        \hline
        75 hiljada & 87.5 \\
    \end{tabular}
\end{table}


\begin{figure}[!htbp]
\centering
    \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/car/image1.png}  \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/car/image2.png}
\caption{Primeri generisanih slika klase \textit{car}}
\label{fig:section4_stylegan_car_images}
\end{figure}


\clearpage
Obuka za klasu \textit{motorbike} je trajala četrdeset osam sati i metodom diferencijabilne augmentacije je generisano četristo hiljada slika. Klasa \textit{motorbike} ima malo lošije rezultate funkcije greške koja je prikazana na slici \ref{fig:section4_stylegan_motorbike_loss}. Funkcija greške generatora raste što ukazuje da diskriminator postaje dosta bolji u prepoznavanju stvarnih od lažnih slika. Slike generisane generatorom nisu savršene, ali moguće je prepoznati glavne karakteristike objekata koji su od značaja za obuku modela detekcije objekata. Rezultat Fréchet-ove udaljenosti (tabela \ref{tab:section4_fid_m}) ukazuje da tokom obuke dolazi do poboljšanja generisanih slika. Primeri generisanih slika klase \textit{motorbike} su prikazani na slici \ref{fig:section4_stylegan_motorbike_images}.


\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/motorbike/g_loss.png}
  \includegraphics[width=0.49\textwidth]{matfmaster/stylegan/motorbike/d_loss.png}
\caption{Funkcije grešaka za klasu \textit{motorbike}, generator (levo) i diskriminator (desno). U oba slučaja, \textit{x} osa predstavlja epohe, dok \textit{y} osa predstavlja vrednosti odgovarajuće funkcije greške. }\label{fig:section4_stylegan_motorbike_loss}
\end{figure}


\begin{table}[!htb]
\caption{Klasa \textit{motorbike}}\label{tab:section4_fid_m}
\centering
    \begin{tabular}{c|c}
        broj epohe &  Fréchet-ova udaljenost \\
        \hline
        25 hiljada & 386.8 \\
        \hline
        100 hiljada & 151.1 \\
    \end{tabular}
\end{table}

\begin{figure}[!htbp]
\centering
    \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/motorbike/image2.png}
    \includegraphics[width=0.45\textwidth]{matfmaster/stylegan/motorbike/image9.png}
\caption{Primeri generisanih slika klase \textit{motoribke}}
\label{fig:section4_stylegan_motorbike_images}
\end{figure}

Generisane slike nisu savršene, ali je moguće prepoznati glavne karakteristike objekata. Neke generisane slike su sklone da sadrže artifakte i zamućenosti.


% #######################################################################
\clearpage
\section{Model za detekciju i predviđanje objekata VGG16}
% #######################################################################

Osnovni model VGG16 je ograničen na klasifikaciju slika bez predviđanja graničnih okvira i u okviru ovog rada osnovni model je proširen odgovarajućim mrežama da se omogući predviđanje graničnih okvira. Osnovni model je proširen na sledeći način:
\begin{itemize}
\item Na poslednji sloj dodato je račvanje na dve nove duboko povezane mreže dubine četiri.
\item Na izlazu prve mreže dodata je aktivaciona funkcija \textit{softmax}  \cite{ml2019} sa četiri neurona, koja se tumači kao dodeljivanje verovatnoće da objekat pripada jednoj od četiri klase.
\item Na izlazu druge mreže dodata je sigmoidna aktivaciona funkcija sa četiri neurona, koja se tumači kao dodeljivanje relativnih graničnih okvira predviđenim objektima.
\end{itemize}
Prošireni osnovni model je obučen na skupu podataka \bvs{} u trajanju od oko deset minuta.

Zbog problema neizbalansiranosti klasa koji se javlja u skupu podataka \bvs, dobija se rezultat modela koji ima visoku pristrasnost ka klasi \textit{car}, kao što se vidi iz tabele \ref{tab:section4_vgg16_confusionmatrix}. Model pogrešno daje izlaze graničnih okvira, kao što je prikazano na slici \ref{fig:section4_vgg16prediction}.

\begin{table}[h!]
    \begin{center}
    \caption{Matrica konfuzije modela VGG16 za IoU prag 0.5 i prag ocene pouzdanosti za prepoznatu klasu 0.5}
    \begin{tabular}{ l|c|c|c|c|c|}
                  & car  & motorbike & bus & truck & bez detekcije \\ \hline
    car           & 85   & 26        & 0   & 1     & 0             \\ 
    motorbike     & 0    & 0         & 0   & 0     & 0             \\ 
    bus           & 0    & 0         & 0   & 0     & 0             \\ 
    truck         & 0    & 0         & 0   & 0     & 0             \\ 
    bez detekcije & 4    & 71        & 1   & 0     & 0             \\ \hline
    \hline
    \end{tabular}
    \label{tab:section4_vgg16_confusionmatrix}
    \end{center}
\end{table}


\begin{figure}
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/car_real.jpg}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/motorbike_real.jpg}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/bus_real.jpg}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/truck_real.jpg}
        \caption{Stvarni okviri}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.35\textwidth}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/car_pred.jpg}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/motorbike_pred.jpg}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/bus_pred.jpg}
        \includegraphics[width=\textwidth]{matfmaster/vgg16_base/truck_pred.jpg}
        \caption{Predviđeni okviri}
    \end{subfigure}
    ~
    \caption{Primeri rezultata modela VGG16 nad test skupom podataka}
    \label{fig:section4_vgg16prediction}
\end{figure}



\clearpage
Rezultati evaluacije modela su dati u tabeli \ref{tab:section4_vgg16_results}. Iz rezultata se vidi da se model se ne ponaša dobro nad celim skupom podataka. Neki od razloga koji utiču da model daje nezadovoljavajuće rezultate je visoka neizbalansiranost između klasa i mala količina dostupnih podataka.
Preciznost klasa u odnosu na IoU prag je prikazana na slici \ref{fig:section4_vgg16_prc}.

Kako je osnovni model VGG16 proširen, ne postoje slobodno dostupne odgovarajuće težine drugog modela koje mogu da se koriste za učenje sa prenosom znanja. 
Korišćenjem proširenog skupa podataka \bvs{standard} ili \bvs{style}, dostupna količina podataka bi i dalje bila nedovoljna. Za obuku modela potrebno je desetine hiljada slika koje ni u proširenim skupovima \bvs{} nisu dostupne. 


\begin{table}[h!]
    \begin{center}
    \caption{Rezultati modela VGG16}
    \begin{tabular}{|m{10em}|c|c|}
        \toprule
        klasa     & prosečna preciznost (jedn.~\ref{eq:ap}) & srednja $F_1$-mera (jedn.~\ref{eq:f1a})  \\ \hline
        \midrule
        car       & 0.95  & 0.57 \\ \hline
        motorbike & 0.0   & 0.0 \\ \hline
        bus       & 0.0   & 0.0 \\ \hline
        truck     & 0.0   & 0.0 \\ \hline
        \bottomrule
        Srednja prosečna preciznost (jedn.~\ref{eq:map}) & \multicolumn{2}{c|}{0.24}  \\ \hline
        Srednja težinska $F_1$-mera (jedn.~\ref{eq:f1wa}) & \multicolumn{2}{c|}{0.27}  \\ \hline
    \end{tabular}
    \label{tab:section4_vgg16_results}
    \end{center}
\end{table}


\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava4/precision_vs_iou_threshold_VGG16.png}
    \caption{Preciznost u odnosu na IoU prag za model VGG16. Za klase \textit{motorbike}, \textit{bus} i \textit{truck} preciznost u svim vrednostima IoU iznosi 0.}
    \label{fig:section4_vgg16_prc}
\end{figure}





% #######################################################################
\clearpage
\section{Model za detekciju i predviđanje objekata YOLO}
% #######################################################################

Kako model VGG16 ne može da d\^{a} zadovoljavajuće rezultate, u okviru rada razmatra se i model za detekciju i predviđanje objekata YOLO. Koriste se dve konfiguracije modela YOLO. Prva konfiguracija modela YOLO služi za poređenje rezultata, i u mogućnosti je da predvidi do osamdeset klasa. Prva konfiguracija je prilagođena za skup podataka COCO (eng.~\textit{common objects in context}). Druga konfiguracija modela YOLO je u stanju da predvidi do četiri klase i prilagođena je za skup podataka \bvs.


% +++++++++++++++++++++++++++++++
\subsection{Predikcija modela YOLO koji je obučen na skupu podataka COCO}
% +++++++++++++++++++++++++++++++

Koristi se model YOLO koji je obučen na skupu podataka COCO koji sadrži osamdeset klasa i 328 hiljada slika. Dalje u radu model YOLO obučen na skupu podataka COCO se označava sa $\yolo_{coco}$. Evaluacija modela se vrši nad test skupom podataka \bvs. Matrica konfuzije je izračunata za vrednost IoU praga 0.5 i za ocenu pouzdanosti veću od 0.5. Tokom računanja prosečne preciznosti i srednje $F_1$-mere nije se uzimala u obzir ocena pouzdanosti klasa. 

Iz rezultata matrice konfuzije (tabela \ref{tab:YOLO4_COCO_confusion_mat}) i metoda evaluacije modela (tabela \ref{tab:YOLO4_COCO_results}) zaključuje se sledeće:
\begin{itemize}
    \item Instance klase \textit{car} model $\yolo_{coco}$ predviđa sa visokom ocenom preciznosti. Predviđena je osamdeset i jedna instanca od ukupno osamdeset i devet. Iz matrice konfuzije može da se vidi da je model $\yolo_{coco}$ za tri instance imao ocenu pouzdanosti manju od 0.5. Takođe, pogrešno se klasifikuje pet instanci kao instance klase \textit{truck}. Prosečna preciznost za klasu \textit{car} iznosi 0.88, dok srednja $F_1$-mera iznosi 0.91.
    \item Instance klase \textit{motorbike} se predviđaju lošije od instanci klase \textit{car}. Model $\yolo_{coco}$ predviđa trideset sedam od ukupno devedeset sedam instanci. Većina instanci, tačnije četrdeset devet, za ocenu pouzdanosti ima vrednost manju od 0.5. Ocene pouzdanosti klase ukazuju da model nije siguran pri predviđanju instanci iz klase \textit{motorbike}. Prosečna preciznost iznosi 0.77 i srednja $F_1$-mera iznosi 0.48.
    \item Klasa \textit{bus} sadrži jednu sliku za test i ona se ne predviđa modelom $\yolo_{coco}$. Prosečna preciznost i srednja $F_1$-mera iznose 0.
    \item Instanca klase \textit{truck} se uspešno predviđa modelom $\yolo_{coco}$. Prosečna preciznost iznosi 1.0 i srednja $F_1$-mera iznosi 0.99.
\end{itemize}


\begin{table}[htb]
    \begin{center}
    \caption{Matrica konfuzije modela $\yolo_{coco}$ za IoU prag 0.5 i prag ocene pouzdanosti za prepoznatu klasu veći od 0.5 }
    \begin{tabular}{ l|c|c|c|c|c|}
                  & car  & motorbike & bus & truck & bez detekcije \\ \hline
    car           & 81   & 0         & 0   & 0     & 0             \\ 
    motorbike     & 0    & 37        & 0   & 0     & 0             \\ 
    bus           & 0    & 0         & 0   & 0     & 0             \\ 
    truck         & 5    & 0         & 0   & 1     & 0             \\ 
    bez detekcije & 3    & 52        & 1   & 0     & 0             \\ \hline
    \hline
    \end{tabular}
    \label{tab:YOLO4_COCO_confusion_mat}
    \end{center}
\end{table}


\begin{table}[htb]
    \begin{center}
    \caption{Rezultati evaluacije modela $\yolo_{coco}$}
        \begin{tabular}{|m{10em}|c|c|}
        \toprule
        klasa     & prosečna preciznost (jedn.~\ref{eq:ap}) & srednja $F_1$-mera (jedn.~\ref{eq:f1a})  \\ \hline
        \midrule
        car       & 0.88  & 0.91 \\ \hline
        motorbike & 0.77  & 0.48 \\ \hline
        bus       & 0.0   & 0.0  \\ \hline
        truck     & 1.0   & 0.99 \\ \hline
        \bottomrule
        Srednja prosečna preciznost (jedn.~\ref{eq:map}) & \multicolumn{2}{c|}{0.66}  \\ \hline
        Srednja težinska $F_1$-mera (jedn.~\ref{eq:f1wa}) & \multicolumn{2}{c|}{0.69}  \\ \hline
    \end{tabular}
    \label{tab:YOLO4_COCO_results}
    \end{center}
\end{table}

\clearpage
Preciznost klasa u odnosu na IoU prag je prikazana na slici \ref{fig:YOLO4_COCO_prc}. Model $\yolo_{coco}$ ima srednju prosečnu preciznost (mAP) koja iznosi 0.66 i srednju težinsku $F_1$-meru koja iznosi 0.69. Kod predviđanja modela $\yolo_{coco}$ možemo da zaključimo da dobro prepoznaje objekte klase \textit{car} i \textit{truck}. Problem koji se uočava kod predviđanja tih klasa je da postoje objekti koji imaju slične karakteristike. Takav problem se može uočiti na slici \ref{fig:YOLO4_COCO_car_vs_truck}. Model $\yolo_{coco}$ je uspešno klasifikovao 40\% instanci klase \textit{motorbike} iz test skupa \bvs. Instanca klase \textit{bus} se ne klasifikuje ispravno modelom  $\yolo_{coco}$.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/glava4/precision_vs_iou_threshold_yolo4.png}
    \caption{Preciznost u odnosu na IoU prag [0.5,1) modela $\yolo_{coco}$}
    \label{fig:YOLO4_COCO_prc}
\end{figure}


\begin{figure}[htbp]
    \centering
      \includegraphics[width=0.49\textwidth]{matfmaster/glava4/carproblem.jpg}
      \includegraphics[width=0.49\textwidth]{matfmaster/glava4/truckproblem.jpg}
    \caption{Slične karakteristike dveju različitih klasa, klasa \textit{car} (levo) i klasa \textit{truck} (desno) } \label{fig:YOLO4_COCO_car_vs_truck}
\end{figure}

Na slici \ref{fig:YOLO4_COCO_predictions} su prikazana neka predviđanja modela $\yolo_{coco}$. Slika prikazuje da su se uspešno detektovali neki od objekata koji pripadaju klasama \textit{car} (gore desno), \textit{motorbike} (sredina desno) i \textit{truck} (dole levo). Na slici koja pripada klasi \textit{motorbike} (sredina levo), uočavamo da je model uspešno detektovao čoveka, ali nije uspeo da detektuje objekat klase \textit{motorbike}, odnosno ocena pouzdanosti je bila veoma mala, tj. iznosila je 0.2. 



\begin{figure}[htbp]
    \centering
      \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/base/car_0.jpg}
      \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/base/car_1.jpg}
      \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/base/motorbike_0.jpg}
      \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/base/motorbike_1.jpg}
      \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/base/truck_0.jpg}
      \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/base/bus_0.jpg}
    \caption{Slike iz test skupa i predviđanja nad njima modelom $\yolo_{coco}$, klasa \textit{car} (gore), klasa \textit{motorbike} (sredina),  klasa \textit{truck} (dole levo) i  klasa \textit{bus} (dole desno). Objekti na slikama bez graničnih okvira nisu uspešno detektovani.} \label{fig:YOLO4_COCO_predictions}
\end{figure}


% +++++++++++++++++++++++++++++++
\clearpage
\subsection{Obuka modela pomoću prenosa znanja}
% +++++++++++++++++++++++++++++++
Radi poboljšanja rezultata, naredni modeli su obučeni koristeći težine modela obučene na skupu podataka COCO. Kako postoji razlika u broju klasa između skupa podataka BVS i COCO skupa, neki delovi težina su odbačeni.

Modeli su obučeni na slikama rezolucije do 512$\times$512. Slikama je nasumično menjana veličina iz intervala 224$\times$224 do 512$\times$512, sa korakom 32$\times$32. Obuka modela je bila ograničena na sto pedeset epoha. Za obuku modela korišćen je optimizator ADAM sa početnom stopom učenja $1e^{-3}$. Tokom obuke modela stopa obuke je množena sa faktorom 0.9. Takođe, postavljena je zastavica za rano zaustavljanje, ukoliko se u deset uzastopnih epoha funkcija greške nije umanjila. Iz skupa za obuku odvojeno je 10\% podataka za validaciju. 


%_______________________________________________________________________________________
\subsubsection{Obuka modela pomoću prenosa znanja na skupu podataka BVS}
%_______________________________________________________________________________________

Za detekciju objekata koristi se model YOLO koji je obučen na skupu podataka \bvs{} koji sadrži četiri klase i 1872 slike. Dalje u radu, model YOLO obučen na skupu podataka \bvs{} se označava sa $\yolo_{\bvs}$. Na slici \ref{fig:YOLO4_BVS_loss} je prikazana funkcija greške i stopa obuke modela $\yolo_{\bvs}$. Iz funkcije greške se vidi da je došlo do ranog zaustavljanja obuke modela nakon devedeset devet epoha. Obuka modela je trajala oko dva sata.

\begin{figure}[htb]
\centering
    \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/epoch_loss.png}
    \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/epoch_learning_rate.png}
\caption{Funkcija greške (levo) i stopa obuke (desno) modela $\yolo_{\bvs}$ }
\label{fig:YOLO4_BVS_loss}
\end{figure}


Iz rezultata matrice konfuzije (tabela \ref{tab:YOLO4_BVS_confusion_matrix}) i metoda evaluacije modela (tabela \ref{tab:YOLO4_BVS_results}) zaključuje se sledeće:
\begin{itemize}
    \item instance klase \textit{car} model $\yolo_{\bvs}$ uspešno predviđa u 100\% slučajeva. Predviđeno je osamdeset devet od osamdeset devet instanci. Prosečna preciznost za klasu \textit{car} iznosi 1.00 i srednja $F_1$-mera iznosi 0.99.
    \item instance klase \textit{motorbike} model takođe uspešno predviđa u 100\% slučajeva. Prosečna preciznost iznosi 1.00 i srednja $F_1$-mera iznosi 0.99, kao i kod klase \textit{car}.
    \item instanca klase \textit{bus} se predviđa kao instanca klase \textit{motorbike}.
    \item instanca klase \textit{truck} se predviđa kao instanca klase \textit{car}.
\end{itemize}


\begin{table}[htb]
    \begin{center}
    \caption{Matrica konfuzije modela $\yolo_{bvs}$ za IoU prag 0.5 i prag ocene pouzdanosti za prepoznatu klasu 0.5 }
    \begin{tabular}{ l|c|c|c|c|c|}
                  & car  & motorbike & bus & truck & bez detekcije \\ \hline
    car           & 89   & 0         & 0   & 1     & 0             \\ 
    motorbike     & 0    & 97        & 1   & 0     & 0             \\ 
    bus           & 0    & 0         & 0   & 0     & 0             \\ 
    truck         & 0    & 0         & 0   & 0     & 0             \\ 
    bez detekcije & 0    & 0         & 0   & 0     & 0             \\ \hline
    \end{tabular}
    \label{tab:YOLO4_BVS_confusion_matrix}
    \end{center}
\end{table}


\begin{table}[htb]
    \begin{center}
    \caption{Rezultati evaluacije modela $\yolo_{bvs}$}
        \begin{tabular}{|m{10em}|c|c|}
        \toprule
        klasa     & prosečna preciznost (jedn.~\ref{eq:ap}) & srednja $F_1$-mera (jedn.~\ref{eq:f1a})  \\ \hline
        \midrule
        car       & 1.00  & 0.99 \\ \hline
        motorbike & 1.00  & 0.99 \\ \hline
        bus       & 0.00  & 0.00 \\ \hline
        truck     & 0.00  & 0.00 \\ \hline
        \bottomrule
        Srednja prosečna preciznost (jedn.~\ref{eq:map}) & \multicolumn{2}{c|}{0.5}  \\ \hline
        Srednja težinska $F_1$-mera (jedn.~\ref{eq:f1wa}) & \multicolumn{2}{c|}{0.97}  \\ \hline
    \end{tabular}
    \label{tab:YOLO4_BVS_results}
    \end{center}
\end{table}

Preciznost klasa u odnosu na IoU prag je prikazana na slici \ref{fig:YOLO4_BVS_prc}. Model $\yolo_{bvs}$ ima srednju prosečnu preciznost (mAP), koja iznosi 0.5 i srednju težinsku $F_1$-meru koja iznosi 0.97. 
Srednja prosečna preciznost je manja u odnosu na model $\yolo_{coco}$. Srednja težinska $F_1$-mera je veća nego kod modela $\yolo_{coco}$ što predstavlja izuzetno poboljšanje. Može se zaključiti da se model ponaša odlično pri detekciji instanci klasa \textit{car} i \textit{motorbike}, dok je za instancu klase \textit{bus} predviđanje pogrešno. Može se primetiti da se problem, pomenut kod modela $\yolo_{coco}$, za neke instance klase \textit{car} i \textit{truck} i dalje javlja. Primer rezultata detekcije je prikazan na slici \ref{fig:YOLO4_BVS_predictions}. Može se zaključiti da model $\yolo_{\bvs}$ daje bolje rezultate od modela $\yolo_{coco}$.



\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/yolo/v4/BVS_set/BVS_prc.png}
    \caption{Preciznost u odnosu na IoU prag [0.5,1) modela $\yolo_{\bvs}$, za klase \textit{bus} i \textit{truck} preciznost u svim vrednostima IoU iznosi 0}
    \label{fig:YOLO4_BVS_prc}
\end{figure}


\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/car_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/car_1.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/motorbike_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/motorbike_1.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/truck_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVS_set/bus_0.jpg}
\caption{Slike iz test skupa i predviđanja nad njima modelom $\yolo_{\bvs}$, klasa \textit{car} (gore), klasa \textit{motorbike} (sredina), klasa \textit{truck} (dole levo) i klasa \textit{bus} (dole desno)}
\label{fig:YOLO4_BVS_predictions}
\end{figure}



%_______________________________________________________________________________________
\clearpage
\subsubsection{Obuka modela pomoću prenosa znanja na skupu podataka \bvs{standard}}
%_______________________________________________________________________________________

Za detekciju objekata koristi se model YOLO koji je obučen na skupu podataka \bvs{standard} koji sadrži četiri klase i 6952 slike. Dalje u radu model YOLO obučen na skupu podataka \bvs{standard} se označava sa $\yolo_{\bvs{standard}}$. Funkcija greške modela i stopa obuke su prikazane na slici \ref{fig:YOLO4_BVSstandard_loss}. Iz funkcije greške se vidi da je došlo do ranog zaustavljanja obuke modela nakon pedeset devet epoha. Obuka modela je trajala deset sati.

\begin{figure}[!ht]
\centering
    \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/epoch_loss.png}
    \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/epoch_learning_rate.png}
\caption{Funkcija greške (levo) i stopa obuke (desno) modela $\yolo_{\bvs{standard}}$ }
\label{fig:YOLO4_BVSstandard_loss}
\end{figure}

Iz rezultata matrice konfuzije (tabela \ref{tab:YOLO4_BVSstandard_confusion_mat}) i metoda evaluacije modela (tabela \ref{tab:YOLO4_BVSstandard_results}) zaključuje se sledeće:
\begin{itemize}
    \item instance klase \textit{car} model $\yolo_{\bvs{standard}}$ predviđa uspešno u 100\% slučajeva (tj.~predviđeno je osamdeset devet od osamdeset devet instanci). Prosečna preciznost za klasu \textit{car} iznosi 1.00, dok srednja $F_1$-mera iznosi 0.99. Ovi rezultati ukazuju na veoma dobro predviđanje modela  $\yolo_{\bvs{standard}}$ nad klasom \textit{car}.
    \item instance klase \textit{motorbike} model predviđa uspešno kao i instance klase \textit{car}. Model  $\yolo_{\bvs{standard}}$ predviđa devedeset sedam od devedeset sedam instanci. Prosečna preciznost iznosi 1.00 i srednja $F_1$-mera iznosi 0.99.
    \item instanca klase \textit{bus} nije predviđena modelom  $\yolo_{\bvs{standard}}$, tačnije ocena pouzdanosti je manja od 0.5.
    \item instanca klasa \textit{truck} se pogrešno predviđa kao instanca klasa \textit{car}. 
\end{itemize}



\begin{table}[htb]
    \begin{center}
    \caption{Matrica konfuzije modela $\yolo_{\bvs{standard}}$ za IoU prag 0.5 i prag pozdanosti za prepoznatu klasu 0.5 }
    \begin{tabular}{ l|c|c|c|c|c|}
                  & car  & motorbike & bus & truck & bez detekcije \\ \hline
    car           & 89   & 0         & 0   & 1     & 0             \\ 
    motorbike     & 0    & 97        & 0   & 0     & 0             \\ 
    bus           & 0    & 0         & 0   & 0     & 0             \\ 
    truck         & 0    & 0         & 0   & 0     & 0             \\ 
    bez detekcije & 0    & 0         & 1   & 0     & 0             \\ \hline
    \hline
    \end{tabular}
    \label{tab:YOLO4_BVSstandard_confusion_mat}
    \end{center}
\end{table}

\begin{table}[htb]
    \begin{center}
    \caption{Rezultati modela $\yolo_{\bvs{standard}}$}
        \begin{tabular}{|m{10em}|c|c|}
        \toprule
        klasa     & prosečna preciznost (jedn.~\ref{eq:ap}) & srednja $F_1$-mera (jedn.~\ref{eq:f1a})  \\ \hline
        \midrule
        car       & 1.00   & 0.99 \\ \hline
        motorbike & 1.00   & 0.99 \\ \hline
        bus       & 0.00   & 0.00 \\ \hline
        truck     & 0.00   & 0.00 \\ \hline
        \bottomrule
        Srednja prosečna preciznost (jedn.~\ref{eq:map}) & \multicolumn{2}{c|}{0.50}  \\ \hline
        Srednja težinska $F_1$-mera (jedn.~\ref{eq:f1wa}) & \multicolumn{2}{c|}{0.97}  \\ \hline
    \end{tabular}
    \label{tab:YOLO4_BVSstandard_results}
    \end{center}
\end{table}

\clearpage
Preciznost klasa u odnosu na IoU prag je prikazana na slici \ref{fig:YOLO4_BVSstandard_prc}. Model $\yolo_{\bvs{standard}}$ ima srednju prosečnu preciznost (mAP), koja iznosi 0.50 i srednju težinsku $F_1$-meru koja iznosi 0.97. Kod predviđanja modela  $\yolo_{\bvs{standard}}$ možemo da zaključimo da dobro prepoznaje objekte klase \textit{car} i \textit{motorbike}. Srednja prosečna preciznost je manja u odnosu na model $\yolo_{coco}$. Rezultati dobijeni modelom $\yolo_{\bvs{standard}}$ su veoma slični sa rezultatima modela $\yolo_{\bvs}$. Primer rezultata detekcije je prikazan na slici \ref{fig:YOLO4_BVSstandard_predictions}. Može se zaključiti da model $\yolo_{\bvs{standard}}$ daje bolje rezultate od modela $\yolo_{coco}$.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/yolo/v4/BVSstandard_set/BVSstandard_prc.png}
    \caption{Preciznost u odnosu na IoU prag [0.5,1) modela $\yolo_{\bvs{standard}}$. Za klase \textit{bus} i \textit{truck} preciznost u svim vrednostima IoU iznosi 0.}
    \label{fig:YOLO4_BVSstandard_prc}
\end{figure}

\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/car_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/car_1.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/motorbike_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/motorbike_1.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/truck_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstandard_set/bus_0.jpg}
\caption{Slike iz test skupa i predviđanja nad njima modelom  $\yolo_{\bvs{standard}}$, klasa \textit{car} (gore), klasa \textit{motorbike} (sredina), klasa \textit{truck} (dole levo) i klasa \textit{bus} (dole desno). Objekti na slikama bez graničnih okvira nisu uspešno detektovani.}\label{fig:YOLO4_BVSstandard_predictions}
\end{figure}


%_______________________________________________________________________________________
\clearpage
\subsubsection{Obuka modela pomoću prenosa znanja na skupu \bvs{style}}
%_______________________________________________________________________________________

Za detekciju objekata koristi se model YOLO koji je obučen na skupu podataka \bvs{style} koji sadrži četiri klase i 6952 slike. Dalje u radu model YOLO obučen na skupu podataka \bvs{style} se označava sa $\yolo_{\bvs{style}}$. Funkcija greške modela je prikazana na slici \ref{fig:YOLO4_BVSstyle_loss}. Iz funkcije greške se vidi da je došlo do ranog zaustavljanja obuke modela nakon pedeset sedam epoha. Obuka modela je trajala oko pet sati.


\begin{figure}[!ht]
\centering
    \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/epoch_loss.png}
    \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/epoch_learning_rate.png}
\caption{Funkcija greške (levo) i stopa obuke (desno) modela $\yolo_{\bvs{style}}$ }
\label{fig:YOLO4_BVSstyle_loss}
\end{figure}

Iz rezultata matrice konfuzije (tabela \ref{tab:YOLO4_BVSstyle_confusion_mat}) i metoda evaluacije modela (tabela \ref{tab:YOLO4_BVSstyle_results}) zaključuje se sledeće:
\begin{itemize}
    \item instance klase \textit{car} model $\yolo_{\bvs{style}}$ predviđa uspešno u 100\% slučajeva (tj.~predviđeno je osamdeset devet od osamdeset devet instanci). Prosečna preciznost za klasu \textit{car} iznosi 1,0, dok srednja $F_1$-mera iznosi 0.99. Ovi rezultati ukazuju na savršeno predviđanje modela $\yolo_{\bvs{style}}$ nad klasom \textit{car}.
    \item instance klase \textit{motorbike} se predviđaju podjednako dobro kao i instance klase \textit{car}. Model $\yolo_{\bvs{style}}$ predviđa devedeset sedam od devedeset sedam instanci. Prosečna preciznost iznosi 1.0 i srednja $F_1$-mera iznosi 0.98.
    \item instancu klase \textit{bus} model $\yolo_{\bvs{style}}$ uspešno predviđa. Prosečna preciznost i srednja $F_1$-mera iznose 1.00.
    \item instancu klase \textit{truck} model pogrešno predviđa kao instancu klase \textit{car}. 
\end{itemize}

\begin{table}[htb]
    \begin{center}
    \caption{Matrica konfuzije modela $\yolo_{\bvs{style}}$ za IoU prag 0.5 i prag pouzdanosti za prepoznatu klasu 0.5 }
    \begin{tabular}{ l|c|c|c|c|c|}
                  & car  & motorbike & bus & truck & bez detekcije \\ \hline
    car           & 89   & 0         & 0   & 1     & 0             \\ 
    motorbike     & 0    & 97        & 0   & 0     & 0             \\ 
    bus           & 0    & 0         & 1   & 0     & 0             \\ 
    truck         & 0    & 0         & 0   & 0     & 0             \\ 
    bez detekcije & 0    & 0         & 0   & 0     & 0             \\ \hline
    \hline
    \end{tabular}
    \label{tab:YOLO4_BVSstyle_confusion_mat}
    \end{center}
\end{table}

\begin{table}[htb]
    \begin{center}
    \caption{Rezultati modela $\yolo_{\bvs{style}}$}
        \begin{tabular}{|m{10em}|c|c|}
        \toprule
        klasa     & prosečna preciznost (jedn.~\ref{eq:ap}) & srednja $F_1$-mera (jedn.~\ref{eq:f1a})  \\ \hline
        \midrule
        car       & 1.00   & 0.99 \\ \hline
        motorbike & 1.00   & 0.98 \\ \hline
        bus       & 1.00   & 1.00 \\ \hline
        truck     & 0.00   & 0.00 \\ \hline
        \bottomrule
        Srednja prosečna preciznost (jedn.~\ref{eq:map}) & \multicolumn{2}{c|}{0.75}  \\ \hline
        Srednja težinska $F_1$-mera (jedn.~\ref{eq:f1wa}) & \multicolumn{2}{c|}{0.98}  \\
        \hline
    \end{tabular}
    \label{tab:YOLO4_BVSstyle_results}
    \end{center}
\end{table}


\clearpage
Preciznost klasa u odnosu na IoU prag je prikazana na slici \ref{fig:YOLO4_BVSstyle_prc}. Model $\yolo_{\bvs{style}}$ ima srednju prosečnu preciznost (mAP), koja iznosi 0.75. Srednja prosečna preciznost je najveća u poređenju sa svim YOLO modelima. Srednja težinska $F_1$-mera iznosi 0.98 i ona takođe, predstavlja najbolji dobijeni rezultat. Kod predviđanja modela $\yolo_{\bvs{style}}$ možemo da zaključimo da dobro predviđa objekte klase \textit{car}, \textit{motorbike} i \textit{bus}. Model $\yolo_{\bvs{style}}$ daje najbolje rezultate. Gubitak, kao i kod modela $\yolo_{\bvs{standard}}$ i $\yolo_{\bvs}$, javlja se u predviđanju instanca klase \textit{truck}. Primer rezultata detekcije je prikazan na slici \ref{fig:YOLO4_BVSstyle_predictions}.



\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{matfmaster/yolo/v4/BVSstyle_set/BVSstyle_prc.png}
    \caption{Preciznost u odnosu na IoU prag [0.5,1) modela $\yolo_{\bvs{style}}$}
    \label{fig:YOLO4_BVSstyle_prc}
\end{figure}


\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/car_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/car_1.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/motorbike_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/motorbike_1.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/truck_0.jpg}
  \includegraphics[width=0.49\textwidth]{matfmaster/yolo/v4/BVSstyle_set/bus_0.jpg}
\caption{Slike iz test skupa i predviđanja nad njima modelom $\yolo_{\bvs{style}}$, klasa \textit{car} (gore), klasa \textit{motorbike} (sredina), klasa \textit{truck} (dole levo) i klasa \textit{bus} (dole desno).}
\label{fig:YOLO4_BVSstyle_predictions}
\end{figure}


% #######################################################################
\clearpage
\section{Komparativna analiza rezultata}
% #######################################################################

Model VGG16 je obučen na podacima \bvs{}, dok je model YOLO obučen na podacima \bvs, \bvs{standard} i \bvs{style}. Dobijeni su rezultati koji su prikazani u tabeli \ref{tab:YOLO4_all_results}.

\begin{table}[htb]
    \begin{center}
    \caption{Rezultati obučenih modela za detekciju objekata}
    \begin{tabular}{ l|c|c|}
                                &  \pbox{5cm}{Srednja prosečna preciznost (jedn.~\ref{eq:map})}          & \pbox{5cm}{Srednja težinska $F_1$-mera (jedn.~\ref{eq:f1wa})}      \\ \hline \hline
    VGG16                       & 0.24         & 0.27         \\ 
    $\yolo_{coco}$              & 0.66         & 0.69         \\ 
    $\yolo_{\bvs}$              & 0.50         & 0.97         \\ 
    $\yolo_{\bvs{standard}}$    & 0.50         & 0.97         \\ 
    $\yolo_{\bvs{style}}$       & 0.75         & 0.98         \\ 
    \hline
    \end{tabular}
    \label{tab:YOLO4_all_results}
    \end{center}
\end{table}


% Rezultati dobijeni modelom VGG16 imaju srednju prosečnu preciznost koja iznosti 0.24, dok srednja težinska $F_1$-mera iznosti 0.27. Model $\yolo_{coco}$ ima srednju prosečnu preciznost koja iznosti 0.66 i srednju težinsku $F_1$-meru koja iznosti 0.69. Model  $\yolo_{\bvs}$ i model $\yolo_{\bvs{standard}}$ imaju iste rezultate koji iznose za srednju prosečnu preciznost 0.50 i srendju težinsku $F_1$-meru 0.97. Model $\yolo_{\bvs{style}}$ za srednju prosečnu preciznost ima vrednost 0.75 i za srednju težinsku $F_1$-meru 0.98.

Na osnovu srednje prosečne preciznosti, za modele navedene u tabeli  \ref{tab:YOLO4_all_results} može da se uoči da najbolje rezultate daje model 
$\yolo_{\bvs{style}}$, dok model VGG16 ne daje zadovoljavajuće rezultate.
Neki od razloga koji utiču da model VGG16 daje nezadovoljavajuće rezultate je visoka neizbalansiranost između klasa i mala količina dostupnih podataka.
Što se tiče modela $\yolo_{\bvs}$ i $\yolo_{\bvs{standard}}$, koji daju iste rezultate za metrike evaluacije, došlo je do neznatnog ali, nedovoljnog poboljšanja kod modela $\yolo_{\bvs{standard}}$ u odnosu na model $\yolo_{\bvs}$. Naime, došlo je do poboljšanja prepoznavanja instance klase \textit{bus}, ali ocena pouzdanosti nije prešla zadati prag (0.5).






% ------------------------------------------------------------------------------
% \chapter{Diskusija}
% ------------------------------------------------------------------------------


% ------------------------------------------------------------------------------
\clearpage
\chapter{Zaključak}
\label{section6}
% ------------------------------------------------------------------------------
U ovom radu je rešavan problem proširivanja skupa podataka koji se koriste za obučavanje modela za detekciju objekata. Skup podataka je proširivan slikama koje su dobijene standardnim transformacijama (translacija, okretanje, menjanje boja i itd.) i sintetički generisanim slikama od strane generativnih suparničkih mreža. Ukupno je dodato oko pet hiljada slika u skup podataka. Tako prošireni skupovi podataka, \bvs{standard} i \bvs{style}, zasebno su korišćeni za obučavanje modela za detekciju objekata YOLO, dok je model VGG16 obučen na originalnom skupu podataka \bvs.
Radi poboljšanja rezultata kod modela YOLO, korišćena je i obuka sa prenosom znanja. Težine modela koje su se koristile su bile naučene na skupu podataka COCO.

Rezultati koji se dobijaju nakon obuke modela YOLO na skupovima podataka \bvs, \bvs{standard} i \bvs{style} su bolji od rezultata koji se dobijaju sa modelom VGG16. Kod modela YOLO koji su obučeni na skupovima podataka \bvs, \bvs{standard} i \bvs{style}, iz rezultata može da se zaključi da se preciznost popravila kod klasa \textit{car} i \textit{motorbike} u odnosu na model $\yolo_{COCO}$. Kod modela YOLO koji je obučen na skupovima podataka \bvs{} i \bvs{standard}, srednja prosečna preciznost je opala jer se instance klase \textit{truck} više ne prepoznaju, što može da bude uzrok deljenja karakteristika klase \textit{truck} sa klasom \textit{car}. Model YOLO koji je obučen na skupu podataka \bvs{style} uspešno predviđa i instancu klase \textit{bus}. Može se zaključiti da model $\yolo_{\bvs{style}}$ daje najbolje rezultate.

Bolji rezultati za detekcije objekta mogu se dobiti povećanjem količine podataka koja je dostupna modelima \textit{StlyeGAN2} i njihovom obukom duži vremenski period. Time bi se skup za obuku proširio kvalitetnijim i raznovrsnijim slikama.
Unapređenje takođe može da se postigne korišćenjem unije skupova podataka \bvs{standard} i \bvs{style}.

Zahvaljujući razvoju novih tehnologija, možda će biti moguće generisati sintetičke podatke potpuno novim metodama. Na primer, modeli \textit{DALL-E 2} \cite{reddy2021dall} i \textit{MidJourney} \cite{midjourney2022} su u stanju da generišu realistične slike na osnovu njihovih opisa u tekstualnom obliku. Ovakav pristup, međutim, zahteva nove podatke, tj.~tekstualne opise slika.


% ------------------------------------------------------------------------------
% Literatura
% ------------------------------------------------------------------------------
\literatura


% ==============================================================================
% Završni deo teze i prilozi
\backmatter
% ==============================================================================


% ------------------------------------------------------------------------------
% Biografija kandidata
\begin{biografija}
  \textbf{Nikola Grulović} (\emph{Beograd, Srbija,
    14. jul 1993.}) je diplomirani Informatičar Univerziteta u Beogradu. Završio je ,,Petu Beogradsku Gimnaziju'', prirodni smer 2012. godine u Beogradu. Matematički fakultet u Beogradu je upisao 2013. godine, smer Informatika i diplomirao je u septembru 2018. godine. Po završetku akademskih studija upisao je master studije, i u toku akademske 2019-2020 položio sve ispite predviđene planom i programom master studija. U periodu od novembra 2020. godine do aprila 2022. godine je radio kao stažista u kompaniji \textit{AM Energia}, Sorokaba, Brazil. Tokom svoj prakse je radio na poboljšanju postojećih sistema i nadogradnjom sistema novim tehnologijama.
\end{biografija}
% ------------------------------------------------------------------------------
\end{document}
 
